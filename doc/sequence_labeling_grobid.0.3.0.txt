citation model
==============

> python3 delft/applications/grobidTagger.py citation train_eval --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10 --input data/sequenceLabelling/grobid/citation/citation-060518.train

training runtime: 40340.819 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
    f1 (micro): 94.82
                  precision    recall  f1-score   support

        <author>     0.9406    0.9421    0.9414       639
     <booktitle>     0.7500    0.7373    0.7436       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9843    0.9843    0.9843       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.7143    0.7895    0.7500        19
         <issue>     0.9275    0.9143    0.9209        70
       <journal>     0.9376    0.9516    0.9445       537
      <location>     0.8778    0.8404    0.8587        94
          <note>     0.8485    0.7179    0.7778        39
         <pages>     0.9793    0.9844    0.9818       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9588    0.9118    0.9347       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7222    0.7647    0.7429        17
         <title>     0.9606    0.9606    0.9606       457
        <volume>     0.9632    0.9850    0.9740       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9472    0.9491    0.9482      3989


------------------------ fold 1 --------------------------------------
    f1 (micro): 95.05
                  precision    recall  f1-score   support

        <author>     0.9498    0.9484    0.9491       639
     <booktitle>     0.7895    0.7627    0.7759       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9900    0.9886    0.9893       699
        <editor>     0.7692    0.7143    0.7407        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9155    0.9286    0.9220        70
       <journal>     0.9353    0.9423    0.9388       537
      <location>     0.8791    0.8511    0.8649        94
          <note>     0.8182    0.6923    0.7500        39
         <pages>     0.9811    0.9896    0.9853       576
     <publisher>     0.9388    0.9200    0.9293        50
        <pubnum>     0.9485    0.9020    0.9246       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7000    0.8235    0.7568        17
         <title>     0.9542    0.9584    0.9563       457
        <volume>     0.9631    0.9812    0.9721       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9499    0.9511    0.9505      3989


------------------------ fold 2 --------------------------------------
    f1 (micro): 95.42
                  precision    recall  f1-score   support

        <author>     0.9561    0.9546    0.9554       639
     <booktitle>     0.7642    0.7966    0.7801       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9843    0.9857    0.9850       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7727    0.8947    0.8293        19
         <issue>     0.9429    0.9429    0.9429        70
       <journal>     0.9461    0.9479    0.9470       537
      <location>     0.9043    0.9043    0.9043        94
          <note>     0.7576    0.6410    0.6944        39
         <pages>     0.9793    0.9878    0.9836       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9697    0.9412    0.9552       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6667    0.7059    0.6857        17
         <title>     0.9604    0.9562    0.9583       457
        <volume>     0.9686    0.9850    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9530    0.9554    0.9542      3989


------------------------ fold 3 --------------------------------------
    f1 (micro): 95.11
                  precision    recall  f1-score   support

        <author>     0.9545    0.9531    0.9538       639
     <booktitle>     0.7563    0.7627    0.7595       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9871    0.9857    0.9864       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.8000    0.8421    0.8205        19
         <issue>     0.9559    0.9286    0.9420        70
       <journal>     0.9357    0.9479    0.9417       537
      <location>     0.8804    0.8617    0.8710        94
          <note>     0.8333    0.6410    0.7246        39
         <pages>     0.9827    0.9861    0.9844       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9300    0.9118    0.9208       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7647    0.7647    0.7647        17
         <title>     0.9582    0.9540    0.9561       457
        <volume>     0.9650    0.9850    0.9749       532
           <web>     0.8333    0.8333    0.8333        12

all (micro avg.)     0.9511    0.9511    0.9511      3989


------------------------ fold 4 --------------------------------------
    f1 (micro): 95.33
                  precision    recall  f1-score   support

        <author>     0.9422    0.9437    0.9429       639
     <booktitle>     0.7750    0.7881    0.7815       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9871    0.9871    0.9871       699
        <editor>     0.7692    0.7143    0.7407        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9414    0.9572    0.9492       537
      <location>     0.9121    0.8830    0.8973        94
          <note>     0.8529    0.7436    0.7945        39
         <pages>     0.9793    0.9878    0.9836       576
     <publisher>     0.9388    0.9200    0.9293        50
        <pubnum>     0.9485    0.9020    0.9246       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6500    0.7647    0.7027        17
         <title>     0.9647    0.9562    0.9604       457
        <volume>     0.9705    0.9887    0.9795       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9522    0.9544    0.9533      3989


------------------------ fold 5 --------------------------------------
    f1 (micro): 95.00
                  precision    recall  f1-score   support

        <author>     0.9437    0.9452    0.9445       639
     <booktitle>     0.7623    0.7881    0.7750       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9843    0.9857    0.9850       699
        <editor>     0.6364    0.5000    0.5600        14
   <institution>     0.7143    0.7895    0.7500        19
         <issue>     0.9420    0.9286    0.9353        70
       <journal>     0.9458    0.9423    0.9440       537
      <location>     0.9111    0.8723    0.8913        94
          <note>     0.8065    0.6410    0.7143        39
         <pages>     0.9793    0.9844    0.9818       576
     <publisher>     0.9057    0.9600    0.9320        50
        <pubnum>     0.9691    0.9216    0.9447       102
        <series>     0.5000    0.5000    0.5000         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9626    0.9562    0.9594       457
        <volume>     0.9651    0.9868    0.9758       532
           <web>     0.8333    0.8333    0.8333        12

all (micro avg.)     0.9496    0.9504    0.9500      3989


------------------------ fold 6 --------------------------------------
    f1 (micro): 95.31
                  precision    recall  f1-score   support

        <author>     0.9577    0.9577    0.9577       639
     <booktitle>     0.7731    0.7797    0.7764       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9871    0.9814    0.9842       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.8500    0.8947    0.8718        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9426    0.9479    0.9452       537
      <location>     0.8696    0.8511    0.8602        94
          <note>     0.7576    0.6410    0.6944        39
         <pages>     0.9793    0.9861    0.9827       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9400    0.9216    0.9307       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7222    0.7647    0.7429        17
         <title>     0.9669    0.9584    0.9626       457
        <volume>     0.9703    0.9831    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9540    0.9521    0.9531      3989


------------------------ fold 7 --------------------------------------
    f1 (micro): 94.70
                  precision    recall  f1-score   support

        <author>     0.9467    0.9452    0.9460       639
     <booktitle>     0.7063    0.7542    0.7295       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9843    0.9886    0.9864       699
        <editor>     0.5625    0.6429    0.6000        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9692    0.9000    0.9333        70
       <journal>     0.9442    0.9460    0.9451       537
      <location>     0.8681    0.8404    0.8541        94
          <note>     0.8387    0.6667    0.7429        39
         <pages>     0.9777    0.9878    0.9827       576
     <publisher>     0.8824    0.9000    0.8911        50
        <pubnum>     0.9495    0.9216    0.9353       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7647    0.7647    0.7647        17
         <title>     0.9559    0.9497    0.9528       457
        <volume>     0.9668    0.9850    0.9758       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9462    0.9479    0.9470      3989


------------------------ fold 8 --------------------------------------
    f1 (micro): 95.12
                  precision    recall  f1-score   support

        <author>     0.9577    0.9577    0.9577       639
     <booktitle>     0.7266    0.7881    0.7561       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9857    0.9871    0.9864       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7500    0.7895    0.7692        19
         <issue>     0.9275    0.9143    0.9209        70
       <journal>     0.9390    0.9460    0.9425       537
      <location>     0.8667    0.8298    0.8478        94
          <note>     0.7941    0.6923    0.7397        39
         <pages>     0.9776    0.9861    0.9818       576
     <publisher>     0.9423    0.9800    0.9608        50
        <pubnum>     0.9588    0.9118    0.9347       102
        <series>     1.0000    0.5000    0.6667         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9621    0.9431    0.9525       457
        <volume>     0.9723    0.9887    0.9804       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9502    0.9521    0.9512      3989


------------------------ fold 9 --------------------------------------
    f1 (micro): 94.66
                  precision    recall  f1-score   support

        <author>     0.9544    0.9499    0.9522       639
     <booktitle>     0.7653    0.6356    0.6944       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9801    0.9843    0.9822       699
        <editor>     0.6154    0.5714    0.5926        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9375    0.9497    0.9436       537
      <location>     0.8723    0.8723    0.8723        94
          <note>     0.8710    0.6923    0.7714        39
         <pages>     0.9760    0.9896    0.9828       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9583    0.9020    0.9293       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9258    0.9562    0.9408       457
        <volume>     0.9668    0.9850    0.9758       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9453    0.9479    0.9466      3989

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

        <author>     0.9544    0.9499    0.9522       639
     <booktitle>     0.7653    0.6356    0.6944       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9801    0.9843    0.9822       699
        <editor>     0.6154    0.5714    0.5926        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9375    0.9497    0.9436       537
      <location>     0.8723    0.8723    0.8723        94
          <note>     0.8710    0.6923    0.7714        39
         <pages>     0.9760    0.9896    0.9828       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9583    0.9020    0.9293       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9258    0.9562    0.9408       457
        <volume>     0.9668    0.9850    0.9758       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9453    0.9479    0.9466      3989


** Best ** model scores - run 2
                  precision    recall  f1-score   support

        <author>     0.9561    0.9546    0.9554       639
     <booktitle>     0.7642    0.7966    0.7801       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9843    0.9857    0.9850       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7727    0.8947    0.8293        19
         <issue>     0.9429    0.9429    0.9429        70
       <journal>     0.9461    0.9479    0.9470       537
      <location>     0.9043    0.9043    0.9043        94
          <note>     0.7576    0.6410    0.6944        39
         <pages>     0.9793    0.9878    0.9836       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9697    0.9412    0.9552       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6667    0.7059    0.6857        17
         <title>     0.9604    0.9562    0.9583       457
        <volume>     0.9686    0.9850    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9530    0.9554    0.9542      3989

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

        <author>     0.9504    0.9498    0.9501       639
     <booktitle>     0.7569    0.7593    0.7572       118
 <collaboration>     0.9636    0.8083    0.8777        12
          <date>     0.9854    0.9858    0.9856       699
        <editor>     0.6666    0.6357    0.6496        14
   <institution>     0.7537    0.8211    0.7857        19
         <issue>     0.9404    0.9200    0.9300        70
       <journal>     0.9405    0.9479    0.9442       537
      <location>     0.8841    0.8606    0.8722        94
          <note>     0.8178    0.6769    0.7404        39
         <pages>     0.9792    0.9870    0.9831       576
     <publisher>     0.9329    0.9380    0.9352        50
        <pubnum>     0.9531    0.9147    0.9335       102
        <series>     0.1500    0.1000    0.1167         2
          <tech>     0.6913    0.7647    0.7251        17
         <title>     0.9572    0.9549    0.9560       457
        <volume>     0.9672    0.9853    0.9762       532
           <web>     0.9038    0.9250    0.9140        12

all (micro avg.)     0.9499    0.9511    0.9505 



> python3 delft/applications/grobidTagger.py citation train_eval --architecture BidLSTM_CRF_FEATURES --embedding glove-840B --fold-count 10 --input data/sequenceLabelling/grobid/citation/citation-060518.train

training runtime: 40409.756 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
    f1 (micro): 95.09
                  precision    recall  f1-score   support

        <author>     0.9498    0.9484    0.9491       639
     <booktitle>     0.7541    0.7797    0.7667       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9858    0.9900    0.9879       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.7143    0.7895    0.7500        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9410    0.9497    0.9453       537
      <location>     0.8804    0.8617    0.8710        94
          <note>     0.8485    0.7179    0.7778        39
         <pages>     0.9777    0.9896    0.9836       576
     <publisher>     0.9388    0.9200    0.9293        50
        <pubnum>     0.9286    0.8922    0.9100       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9560    0.9519    0.9539       457
        <volume>     0.9741    0.9887    0.9813       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9495    0.9524    0.9509      3989


------------------------ fold 1 --------------------------------------
    f1 (micro): 94.71
                  precision    recall  f1-score   support

        <author>     0.9420    0.9405    0.9413       639
     <booktitle>     0.7258    0.7627    0.7438       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9871    0.9857    0.9864       699
        <editor>     0.7692    0.7143    0.7407        14
   <institution>     0.7143    0.7895    0.7500        19
         <issue>     0.9403    0.9000    0.9197        70
       <journal>     0.9428    0.9516    0.9472       537
      <location>     0.8778    0.8404    0.8587        94
          <note>     0.7429    0.6667    0.7027        39
         <pages>     0.9693    0.9861    0.9776       576
     <publisher>     0.9388    0.9200    0.9293        50
        <pubnum>     0.9495    0.9216    0.9353       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7647    0.7647    0.7647        17
         <title>     0.9538    0.9497    0.9518       457
        <volume>     0.9650    0.9850    0.9749       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9457    0.9484    0.9471      3989


------------------------ fold 2 --------------------------------------
    f1 (micro): 94.97
                  precision    recall  f1-score   support

        <author>     0.9577    0.9577    0.9577       639
     <booktitle>     0.7541    0.7797    0.7667       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9885    0.9871    0.9878       699
        <editor>     0.6000    0.6429    0.6207        14
   <institution>     0.6190    0.6842    0.6500        19
         <issue>     0.9167    0.9429    0.9296        70
       <journal>     0.9339    0.9479    0.9409       537
      <location>     0.8889    0.8511    0.8696        94
          <note>     0.7941    0.6923    0.7397        39
         <pages>     0.9659    0.9844    0.9751       576
     <publisher>     0.9200    0.9200    0.9200        50
        <pubnum>     0.9583    0.9020    0.9293       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7647    0.7647    0.7647        17
         <title>     0.9558    0.9475    0.9516       457
        <volume>     0.9721    0.9831    0.9776       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9483    0.9511    0.9497      3989


------------------------ fold 3 --------------------------------------
    f1 (micro): 94.97
                  precision    recall  f1-score   support

        <author>     0.9437    0.9452    0.9445       639
     <booktitle>     0.7479    0.7542    0.7511       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9886    0.9900    0.9893       699
        <editor>     0.7692    0.7143    0.7407        14
   <institution>     0.7500    0.7895    0.7692        19
         <issue>     0.9701    0.9286    0.9489        70
       <journal>     0.9291    0.9516    0.9402       537
      <location>     0.8901    0.8617    0.8757        94
          <note>     0.7879    0.6667    0.7222        39
         <pages>     0.9777    0.9896    0.9836       576
     <publisher>     0.9583    0.9200    0.9388        50
        <pubnum>     0.9592    0.9216    0.9400       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9578    0.9431    0.9504       457
        <volume>     0.9686    0.9868    0.9777       532
           <web>     0.7692    0.8333    0.8000        12

all (micro avg.)     0.9487    0.9506    0.9497      3989


------------------------ fold 4 --------------------------------------
    f1 (micro): 95.01
                  precision    recall  f1-score   support

        <author>     0.9530    0.9515    0.9522       639
     <booktitle>     0.7311    0.7373    0.7342       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9899    0.9857    0.9878       699
        <editor>     0.6250    0.7143    0.6667        14
   <institution>     0.7273    0.8421    0.7805        19
         <issue>     0.9701    0.9286    0.9489        70
       <journal>     0.9375    0.9497    0.9436       537
      <location>     0.8977    0.8404    0.8681        94
          <note>     0.7632    0.7436    0.7532        39
         <pages>     0.9760    0.9878    0.9819       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9300    0.9118    0.9208       102
        <series>     0.2500    0.5000    0.3333         2
          <tech>     0.6667    0.7059    0.6857        17
         <title>     0.9665    0.9475    0.9569       457
        <volume>     0.9703    0.9831    0.9767       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9497    0.9506    0.9501      3989


------------------------ fold 5 --------------------------------------
    f1 (micro): 94.82
                  precision    recall  f1-score   support

        <author>     0.9422    0.9437    0.9429       639
     <booktitle>     0.7632    0.7373    0.7500       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9801    0.9886    0.9843       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7895    0.7895    0.7895        19
         <issue>     0.9701    0.9286    0.9489        70
       <journal>     0.9303    0.9441    0.9372       537
      <location>     0.8913    0.8723    0.8817        94
          <note>     0.8065    0.6410    0.7143        39
         <pages>     0.9777    0.9896    0.9836       576
     <publisher>     0.9600    0.9600    0.9600        50
        <pubnum>     0.9293    0.9020    0.9154       102
        <series>     0.2500    0.5000    0.3333         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9561    0.9540    0.9551       457
        <volume>     0.9667    0.9831    0.9748       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9470    0.9494    0.9482      3989


------------------------ fold 6 --------------------------------------
    f1 (micro): 95.10
                  precision    recall  f1-score   support

        <author>     0.9469    0.9484    0.9476       639
     <booktitle>     0.8000    0.7458    0.7719       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9830    0.9914    0.9872       699
        <editor>     0.6154    0.5714    0.5926        14
   <institution>     0.7500    0.7895    0.7692        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9341    0.9497    0.9418       537
      <location>     0.8791    0.8511    0.8649        94
          <note>     0.8065    0.6410    0.7143        39
         <pages>     0.9810    0.9878    0.9844       576
     <publisher>     0.9020    0.9200    0.9109        50
        <pubnum>     0.9490    0.9118    0.9300       102
        <series>     0.5000    0.5000    0.5000         2
          <tech>     0.7222    0.7647    0.7429        17
         <title>     0.9564    0.9606    0.9585       457
        <volume>     0.9704    0.9850    0.9776       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9504    0.9516    0.9510      3989


------------------------ fold 7 --------------------------------------
    f1 (micro): 94.70
                  precision    recall  f1-score   support

        <author>     0.9330    0.9374    0.9352       639
     <booktitle>     0.7521    0.7712    0.7615       118
 <collaboration>     0.9000    0.7500    0.8182        12
          <date>     0.9801    0.9871    0.9836       699
        <editor>     0.5556    0.3571    0.4348        14
   <institution>     0.6667    0.7368    0.7000        19
         <issue>     0.9420    0.9286    0.9353        70
       <journal>     0.9376    0.9516    0.9445       537
      <location>     0.8889    0.8511    0.8696        94
          <note>     0.7941    0.6923    0.7397        39
         <pages>     0.9793    0.9844    0.9818       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9588    0.9118    0.9347       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7000    0.8235    0.7568        17
         <title>     0.9645    0.9519    0.9581       457
        <volume>     0.9721    0.9812    0.9766       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9464    0.9476    0.9470      3989


------------------------ fold 8 --------------------------------------
    f1 (micro): 95.22
                  precision    recall  f1-score   support

        <author>     0.9468    0.9468    0.9468       639
     <booktitle>     0.7928    0.7458    0.7686       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9858    0.9900    0.9879       699
        <editor>     0.5714    0.5714    0.5714        14
   <institution>     0.7273    0.8421    0.7805        19
         <issue>     0.9701    0.9286    0.9489        70
       <journal>     0.9394    0.9534    0.9464       537
      <location>     0.8764    0.8298    0.8525        94
          <note>     0.8235    0.7179    0.7671        39
         <pages>     0.9794    0.9913    0.9853       576
     <publisher>     0.9020    0.9200    0.9109        50
        <pubnum>     0.9495    0.9216    0.9353       102
        <series>     0.3333    0.5000    0.4000         2
          <tech>     0.7500    0.7059    0.7273        17
         <title>     0.9564    0.9606    0.9585       457
        <volume>     0.9776    0.9831    0.9803       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9521    0.9524    0.9522      3989


------------------------ fold 9 --------------------------------------
    f1 (micro): 95.16
                  precision    recall  f1-score   support

        <author>     0.9514    0.9499    0.9507       639
     <booktitle>     0.7480    0.7797    0.7635       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9885    0.9857    0.9871       699
        <editor>     0.6000    0.6429    0.6207        14
   <institution>     0.7273    0.8421    0.7805        19
         <issue>     0.9697    0.9143    0.9412        70
       <journal>     0.9464    0.9534    0.9499       537
      <location>     0.8681    0.8404    0.8541        94
          <note>     0.8387    0.6667    0.7429        39
         <pages>     0.9760    0.9878    0.9819       576
     <publisher>     0.9200    0.9200    0.9200        50
        <pubnum>     0.9490    0.9118    0.9300       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9690    0.9562    0.9626       457
        <volume>     0.9669    0.9868    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9512    0.9521    0.9516      3989

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

        <author>     0.9330    0.9374    0.9352       639
     <booktitle>     0.7521    0.7712    0.7615       118
 <collaboration>     0.9000    0.7500    0.8182        12
          <date>     0.9801    0.9871    0.9836       699
        <editor>     0.5556    0.3571    0.4348        14
   <institution>     0.6667    0.7368    0.7000        19
         <issue>     0.9420    0.9286    0.9353        70
       <journal>     0.9376    0.9516    0.9445       537
      <location>     0.8889    0.8511    0.8696        94
          <note>     0.7941    0.6923    0.7397        39
         <pages>     0.9793    0.9844    0.9818       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9588    0.9118    0.9347       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7000    0.8235    0.7568        17
         <title>     0.9645    0.9519    0.9581       457
        <volume>     0.9721    0.9812    0.9766       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9464    0.9476    0.9470      3989


** Best ** model scores - run 8
                  precision    recall  f1-score   support

        <author>     0.9468    0.9468    0.9468       639
     <booktitle>     0.7928    0.7458    0.7686       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9858    0.9900    0.9879       699
        <editor>     0.5714    0.5714    0.5714        14
   <institution>     0.7273    0.8421    0.7805        19
         <issue>     0.9701    0.9286    0.9489        70
       <journal>     0.9394    0.9534    0.9464       537
      <location>     0.8764    0.8298    0.8525        94
          <note>     0.8235    0.7179    0.7671        39
         <pages>     0.9794    0.9913    0.9853       576
     <publisher>     0.9020    0.9200    0.9109        50
        <pubnum>     0.9495    0.9216    0.9353       102
        <series>     0.3333    0.5000    0.4000         2
          <tech>     0.7500    0.7059    0.7273        17
         <title>     0.9564    0.9606    0.9585       457
        <volume>     0.9776    0.9831    0.9803       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9521    0.9524    0.9522      3989

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

        <author>     0.9467    0.9469    0.9468       639
     <booktitle>     0.7569    0.7593    0.7578       118
 <collaboration>     0.9900    0.7917    0.8792        12
          <date>     0.9857    0.9881    0.9869       699
        <editor>     0.6441    0.6214    0.6298        14
   <institution>     0.7186    0.7895    0.7519        19
         <issue>     0.9532    0.9229    0.9376        70
       <journal>     0.9372    0.9503    0.9437       537
      <location>     0.8839    0.8500    0.8666        94
          <note>     0.8006    0.6846    0.7374        39
         <pages>     0.9760    0.9878    0.9819       576
     <publisher>     0.9283    0.9280    0.9281        50
        <pubnum>     0.9461    0.9108    0.9281       102
        <series>     0.1333    0.2000    0.1567         2
          <tech>     0.7040    0.7588    0.7293        17
         <title>     0.9593    0.9523    0.9557       457
        <volume>     0.9704    0.9846    0.9774       532
           <web>     0.9282    0.9417    0.9347        12

all (micro avg.)     0.9489    0.9506    0.9498 


> python3 delft/applications/grobidTagger.py citation train_eval --architecture BERT_CRF --transformer allenai/scibert_scivocab_cased --input data/sequenceLabelling/grobid/citation/citation-060518.train --fold-count 10

training runtime: 22498.037 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights0.hdf5
  f1 (micro): 94.84
                  precision    recall  f1-score   support

        <author>     0.9531    0.9546    0.9539       639
     <booktitle>     0.6620    0.7966    0.7231       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9870    0.9813    0.9842       697
        <editor>     0.6875    0.7857    0.7333        14
   <institution>     0.5652    0.6842    0.6190        19
         <issue>     0.9420    0.9286    0.9353        70
       <journal>     0.9361    0.9571    0.9465       536
      <location>     0.9278    0.9574    0.9424        94
          <note>     0.6842    0.6667    0.6753        39
         <pages>     0.9793    0.9861    0.9827       576
     <publisher>     0.9200    0.9200    0.9200        50
        <pubnum>     0.9231    0.9505    0.9366       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5238    0.6471    0.5789        17
         <title>     0.9536    0.9474    0.9505       456
        <volume>     0.9777    0.9868    0.9822       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9418    0.9551    0.9484      3984


------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights1.hdf5
  f1 (micro): 95.52
                  precision    recall  f1-score   support

        <author>     0.9592    0.9577    0.9585       639
     <booktitle>     0.7760    0.8220    0.7984       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9871    0.9842    0.9856       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9315    0.9714    0.9510        70
       <journal>     0.9521    0.9646    0.9583       536
      <location>     0.8713    0.9362    0.9026        94
          <note>     0.6750    0.6923    0.6835        39
         <pages>     0.9827    0.9878    0.9853       576
     <publisher>     0.9057    0.9600    0.9320        50
        <pubnum>     0.9223    0.9406    0.9314       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5455    0.7059    0.6154        17
         <title>     0.9670    0.9649    0.9660       456
        <volume>     0.9758    0.9850    0.9804       532
           <web>     0.7692    0.8333    0.8000        12

all (micro avg.)     0.9499    0.9606    0.9552      3984


------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights2.hdf5
  f1 (micro): 95.12
                  precision    recall  f1-score   support

        <author>     0.9457    0.9531    0.9493       639
     <booktitle>     0.8103    0.7966    0.8034       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9828    0.9813    0.9821       697
        <editor>     0.6471    0.7857    0.7097        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9067    0.9714    0.9379        70
       <journal>     0.9401    0.9664    0.9531       536
      <location>     0.8947    0.9043    0.8995        94
          <note>     0.6471    0.5641    0.6027        39
         <pages>     0.9709    0.9861    0.9785       576
     <publisher>     0.9200    0.9200    0.9200        50
        <pubnum>     0.9126    0.9307    0.9216       101
        <series>     0.2500    0.5000    0.3333         2
          <tech>     0.5455    0.7059    0.6154        17
         <title>     0.9653    0.9759    0.9706       456
        <volume>     0.9774    0.9774    0.9774       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9459    0.9566    0.9512      3984


------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights3.hdf5
  f1 (micro): 95.16
                  precision    recall  f1-score   support

        <author>     0.9473    0.9562    0.9517       639
     <booktitle>     0.7348    0.8220    0.7760       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9914    0.9885    0.9899       697
        <editor>     0.6111    0.7857    0.6875        14
   <institution>     0.6000    0.6316    0.6154        19
         <issue>     0.9429    0.9429    0.9429        70
       <journal>     0.9535    0.9571    0.9553       536
      <location>     0.9278    0.9574    0.9424        94
          <note>     0.6905    0.7436    0.7160        39
         <pages>     0.9776    0.9844    0.9810       576
     <publisher>     0.8800    0.8800    0.8800        50
        <pubnum>     0.9223    0.9406    0.9314       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5714    0.7059    0.6316        17
         <title>     0.9481    0.9605    0.9542       456
        <volume>     0.9704    0.9850    0.9776       532
           <web>     0.8333    0.8333    0.8333        12

all (micro avg.)     0.9450    0.9583    0.9516      3984


------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights4.hdf5
  f1 (micro): 95.15
                  precision    recall  f1-score   support

        <author>     0.9564    0.9609    0.9586       639
     <booktitle>     0.7500    0.7881    0.7686       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9899    0.9842    0.9871       697
        <editor>     0.6250    0.7143    0.6667        14
   <institution>     0.5652    0.6842    0.6190        19
         <issue>     0.9296    0.9429    0.9362        70
       <journal>     0.9485    0.9627    0.9556       536
      <location>     0.8958    0.9149    0.9053        94
          <note>     0.6757    0.6410    0.6579        39
         <pages>     0.9810    0.9878    0.9844       576
     <publisher>     0.8462    0.8800    0.8627        50
        <pubnum>     0.9223    0.9406    0.9314       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5652    0.7647    0.6500        17
         <title>     0.9527    0.9715    0.9620       456
        <volume>     0.9739    0.9812    0.9775       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9453    0.9578    0.9515      3984


------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights5.hdf5
  f1 (micro): 95.19
                  precision    recall  f1-score   support

        <author>     0.9549    0.9609    0.9579       639
     <booktitle>     0.7823    0.8220    0.8017       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9828    0.9813    0.9821       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.7000    0.7368    0.7179        19
         <issue>     0.9054    0.9571    0.9306        70
       <journal>     0.9503    0.9627    0.9564       536
      <location>     0.8969    0.9255    0.9110        94
          <note>     0.6923    0.6923    0.6923        39
         <pages>     0.9758    0.9809    0.9784       576
     <publisher>     0.8800    0.8800    0.8800        50
        <pubnum>     0.9048    0.9406    0.9223       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5217    0.7059    0.6000        17
         <title>     0.9545    0.9671    0.9608       456
        <volume>     0.9702    0.9793    0.9747       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9460    0.9578    0.9519      3984


------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights6.hdf5
  f1 (micro): 95.38
                  precision    recall  f1-score   support

        <author>     0.9547    0.9562    0.9554       639
     <booktitle>     0.7419    0.7797    0.7603       118
 <collaboration>     0.7692    0.8333    0.8000        12
          <date>     0.9856    0.9799    0.9827       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.5455    0.6316    0.5854        19
         <issue>     0.9167    0.9429    0.9296        70
       <journal>     0.9593    0.9664    0.9628       536
      <location>     0.8878    0.9255    0.9062        94
          <note>     0.6750    0.6923    0.6835        39
         <pages>     0.9776    0.9844    0.9810       576
     <publisher>     0.8302    0.8800    0.8544        50
        <pubnum>     0.9700    0.9604    0.9652       101
        <series>     0.3333    0.5000    0.4000         2
          <tech>     0.6000    0.7059    0.6486        17
         <title>     0.9675    0.9803    0.9739       456
        <volume>     0.9757    0.9831    0.9794       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9491    0.9586    0.9538      3984


------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights7.hdf5
  f1 (micro): 94.72
                  precision    recall  f1-score   support

        <author>     0.9427    0.9531    0.9479       639
     <booktitle>     0.7661    0.8051    0.7851       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9856    0.9842    0.9849       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6190    0.6842    0.6500        19
         <issue>     0.9054    0.9571    0.9306        70
       <journal>     0.9433    0.9627    0.9529       536
      <location>     0.8469    0.8830    0.8646        94
          <note>     0.7297    0.6923    0.7105        39
         <pages>     0.9743    0.9861    0.9802       576
     <publisher>     0.8600    0.8600    0.8600        50
        <pubnum>     0.9412    0.9505    0.9458       101
        <series>     0.1000    0.5000    0.1667         2
          <tech>     0.5714    0.7059    0.6316        17
         <title>     0.9358    0.9583    0.9469       456
        <volume>     0.9738    0.9774    0.9756       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9395    0.9551    0.9472      3984


------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights8.hdf5
  f1 (micro): 94.78
                  precision    recall  f1-score   support

        <author>     0.9502    0.9546    0.9524       639
     <booktitle>     0.7398    0.7712    0.7552       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9871    0.9842    0.9856       697
        <editor>     0.6875    0.7857    0.7333        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9467    0.9608    0.9537       536
      <location>     0.8725    0.9468    0.9082        94
          <note>     0.6579    0.6410    0.6494        39
         <pages>     0.9726    0.9844    0.9784       576
     <publisher>     0.8776    0.8600    0.8687        50
        <pubnum>     0.9135    0.9406    0.9268       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5000    0.7059    0.5854        17
         <title>     0.9400    0.9627    0.9512       456
        <volume>     0.9703    0.9831    0.9767       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9409    0.9548    0.9478      3984


------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights9.hdf5
  f1 (micro): 94.80
                  precision    recall  f1-score   support

        <author>     0.9455    0.9499    0.9477       639
     <booktitle>     0.7087    0.7627    0.7347       118
 <collaboration>     0.9167    0.9167    0.9167        12
          <date>     0.9856    0.9813    0.9835       697
        <editor>     0.6111    0.7857    0.6875        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9306    0.9571    0.9437        70
       <journal>     0.9468    0.9627    0.9547       536
      <location>     0.8713    0.9362    0.9026        94
          <note>     0.7297    0.6923    0.7105        39
         <pages>     0.9810    0.9844    0.9827       576
     <publisher>     0.8269    0.8600    0.8431        50
        <pubnum>     0.9327    0.9604    0.9463       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5238    0.6471    0.5789        17
         <title>     0.9426    0.9715    0.9568       456
        <volume>     0.9703    0.9831    0.9767       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9400    0.9561    0.9480      3984

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

        <author>     0.9427    0.9531    0.9479       639
     <booktitle>     0.7661    0.8051    0.7851       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9856    0.9842    0.9849       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6190    0.6842    0.6500        19
         <issue>     0.9054    0.9571    0.9306        70
       <journal>     0.9433    0.9627    0.9529       536
      <location>     0.8469    0.8830    0.8646        94
          <note>     0.7297    0.6923    0.7105        39
         <pages>     0.9743    0.9861    0.9802       576
     <publisher>     0.8600    0.8600    0.8600        50
        <pubnum>     0.9412    0.9505    0.9458       101
        <series>     0.1000    0.5000    0.1667         2
          <tech>     0.5714    0.7059    0.6316        17
         <title>     0.9358    0.9583    0.9469       456
        <volume>     0.9738    0.9774    0.9756       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9395    0.9551    0.9472      3984


** Best ** model scores - run 1
                  precision    recall  f1-score   support

        <author>     0.9592    0.9577    0.9585       639
     <booktitle>     0.7760    0.8220    0.7984       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9871    0.9842    0.9856       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9315    0.9714    0.9510        70
       <journal>     0.9521    0.9646    0.9583       536
      <location>     0.8713    0.9362    0.9026        94
          <note>     0.6750    0.6923    0.6835        39
         <pages>     0.9827    0.9878    0.9853       576
     <publisher>     0.9057    0.9600    0.9320        50
        <pubnum>     0.9223    0.9406    0.9314       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5455    0.7059    0.6154        17
         <title>     0.9670    0.9649    0.9660       456
        <volume>     0.9758    0.9850    0.9804       532
           <web>     0.7692    0.8333    0.8000        12

all (micro avg.)     0.9499    0.9606    0.9552      3984

loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF/model_weights1.hdf5
----------------------------------------------------------------------

Average over 2 folds
                  precision    recall  f1-score   support

        <author>     0.9510    0.9557    0.9533       639
     <booktitle>     0.7472    0.7966    0.7706       118
 <collaboration>     0.8580    0.8417    0.8492        12
          <date>     0.9865    0.9831    0.9848       697
        <editor>     0.6803    0.7786    0.7252        14
   <institution>     0.6195    0.6789    0.6473        19
         <issue>     0.9252    0.9486    0.9365        70
       <journal>     0.9477    0.9623    0.9549       536
      <location>     0.8893    0.9287    0.9085        94
          <note>     0.6857    0.6718    0.6782        39
         <pages>     0.9773    0.9852    0.9812       576
     <publisher>     0.8746    0.8900    0.8821        50
        <pubnum>     0.9265    0.9455    0.9359       101
        <series>     0.0683    0.1500    0.0900         2
          <tech>     0.5468    0.7000    0.6136        17
         <title>     0.9527    0.9660    0.9593       456
        <volume>     0.9736    0.9821    0.9778       532
           <web>     0.8654    0.9000    0.8820        12

all (micro avg.)     0.9443    0.9571    0.9507


> python3 delft/applications/grobidTagger.py citation train_eval --architecture BERT_CRF_FEATURES --transformer allenai/scibert_scivocab_cased --input data/sequenceLabelling/grobid/citation/citation-060518.train --fold-count 10

training runtime: 39049.582 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights0.hdf5
  f1 (micro): 95.15
                  precision    recall  f1-score   support

        <author>     0.9594    0.9609    0.9601       639
     <booktitle>     0.7769    0.7966    0.7866       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9856    0.9813    0.9835       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6316    0.6316    0.6316        19
         <issue>     0.8421    0.9143    0.8767        70
       <journal>     0.9498    0.9534    0.9516       536
      <location>     0.8878    0.9255    0.9062        94
          <note>     0.6905    0.7436    0.7160        39
         <pages>     0.9826    0.9826    0.9826       576
     <publisher>     0.8333    0.9000    0.8654        50
        <pubnum>     0.9505    0.9505    0.9505       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5500    0.6471    0.5946        17
         <title>     0.9544    0.9649    0.9597       456
        <volume>     0.9685    0.9812    0.9748       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9473    0.9558    0.9515      3984


------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights1.hdf5
  f1 (micro): 95.01
                  precision    recall  f1-score   support

        <author>     0.9594    0.9609    0.9601       639
     <booktitle>     0.7209    0.7881    0.7530       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9899    0.9857    0.9878       697
        <editor>     0.6875    0.7857    0.7333        14
   <institution>     0.6364    0.7368    0.6829        19
         <issue>     0.8933    0.9571    0.9241        70
       <journal>     0.9518    0.9571    0.9544       536
      <location>     0.8866    0.9149    0.9005        94
          <note>     0.7105    0.6923    0.7013        39
         <pages>     0.9793    0.9861    0.9827       576
     <publisher>     0.8800    0.8800    0.8800        50
        <pubnum>     0.9406    0.9406    0.9406       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9358    0.9583    0.9469       456
        <volume>     0.9685    0.9812    0.9748       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9436    0.9568    0.9501      3984


------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights2.hdf5
  f1 (micro): 94.91
                  precision    recall  f1-score   support

        <author>     0.9470    0.9515    0.9493       639
     <booktitle>     0.7500    0.8136    0.7805       118
 <collaboration>     0.7692    0.8333    0.8000        12
          <date>     0.9857    0.9857    0.9857       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.7368    0.7368    0.7368        19
         <issue>     0.9041    0.9429    0.9231        70
       <journal>     0.9519    0.9590    0.9554       536
      <location>     0.9043    0.9043    0.9043        94
          <note>     0.6667    0.7179    0.6914        39
         <pages>     0.9775    0.9826    0.9801       576
     <publisher>     0.8364    0.9200    0.8762        50
        <pubnum>     0.9231    0.9505    0.9366       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6000    0.7059    0.6486        17
         <title>     0.9560    0.9539    0.9550       456
        <volume>     0.9665    0.9774    0.9720       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9432    0.9551    0.9491      3984


------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights3.hdf5
  f1 (micro): 95.05
                  precision    recall  f1-score   support

        <author>     0.9498    0.9484    0.9491       639
     <booktitle>     0.7833    0.7966    0.7899       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9856    0.9842    0.9849       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.7222    0.6842    0.7027        19
         <issue>     0.9167    0.9429    0.9296        70
       <journal>     0.9499    0.9552    0.9526       536
      <location>     0.8980    0.9362    0.9167        94
          <note>     0.6829    0.7179    0.7000        39
         <pages>     0.9827    0.9861    0.9844       576
     <publisher>     0.8846    0.9200    0.9020        50
        <pubnum>     0.9048    0.9406    0.9223       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.4783    0.6471    0.5500        17
         <title>     0.9459    0.9583    0.9521       456
        <volume>     0.9776    0.9831    0.9803       532
           <web>     0.7692    0.8333    0.8000        12

all (micro avg.)     0.9463    0.9548    0.9505      3984


------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights4.hdf5
  f1 (micro): 95.12
                  precision    recall  f1-score   support

        <author>     0.9654    0.9593    0.9623       639
     <booktitle>     0.7302    0.7797    0.7541       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9856    0.9842    0.9849       697
        <editor>     0.6471    0.7857    0.7097        14
   <institution>     0.6667    0.7368    0.7000        19
         <issue>     0.8462    0.9429    0.8919        70
       <journal>     0.9448    0.9571    0.9509       536
      <location>     0.8571    0.8936    0.8750        94
          <note>     0.6250    0.6410    0.6329        39
         <pages>     0.9861    0.9861    0.9861       576
     <publisher>     0.8333    0.9000    0.8654        50
        <pubnum>     0.9798    0.9604    0.9700       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9629    0.9671    0.9650       456
        <volume>     0.9720    0.9793    0.9757       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9461    0.9563    0.9512      3984


------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights5.hdf5
  f1 (micro): 94.97
                  precision    recall  f1-score   support

        <author>     0.9579    0.9609    0.9594       639
     <booktitle>     0.7008    0.7542    0.7265       118
 <collaboration>     0.8182    0.7500    0.7826        12
          <date>     0.9856    0.9813    0.9835       697
        <editor>     0.7143    0.7143    0.7143        14
   <institution>     0.7222    0.6842    0.7027        19
         <issue>     0.8101    0.9143    0.8591        70
       <journal>     0.9626    0.9608    0.9617       536
      <location>     0.8600    0.9149    0.8866        94
          <note>     0.7000    0.7179    0.7089        39
         <pages>     0.9809    0.9826    0.9818       576
     <publisher>     0.9375    0.9000    0.9184        50
        <pubnum>     0.9231    0.9505    0.9366       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5714    0.7059    0.6316        17
         <title>     0.9566    0.9671    0.9618       456
        <volume>     0.9647    0.9756    0.9701       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9451    0.9543    0.9497      3984


------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights6.hdf5
  f1 (micro): 94.60
                  precision    recall  f1-score   support

        <author>     0.9501    0.9531    0.9516       639
     <booktitle>     0.7015    0.7966    0.7460       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9757    0.9813    0.9785       697
        <editor>     0.7143    0.7143    0.7143        14
   <institution>     0.6842    0.6842    0.6842        19
         <issue>     0.8205    0.9143    0.8649        70
       <journal>     0.9393    0.9534    0.9463       536
      <location>     0.9247    0.9149    0.9198        94
          <note>     0.6829    0.7179    0.7000        39
         <pages>     0.9775    0.9826    0.9801       576
     <publisher>     0.8679    0.9200    0.8932        50
        <pubnum>     0.9048    0.9406    0.9223       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.4800    0.7059    0.5714        17
         <title>     0.9648    0.9605    0.9626       456
        <volume>     0.9665    0.9774    0.9720       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9387    0.9533    0.9460      3984


------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights7.hdf5
  f1 (micro): 95.40
                  precision    recall  f1-score   support

        <author>     0.9592    0.9562    0.9577       639
     <booktitle>     0.7731    0.7797    0.7764       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9870    0.9828    0.9849       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6190    0.6842    0.6500        19
         <issue>     0.9067    0.9714    0.9379        70
       <journal>     0.9538    0.9627    0.9582       536
      <location>     0.8763    0.9043    0.8901        94
          <note>     0.7297    0.6923    0.7105        39
         <pages>     0.9810    0.9861    0.9835       576
     <publisher>     0.9184    0.9000    0.9091        50
        <pubnum>     0.9417    0.9604    0.9510       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5714    0.7059    0.6316        17
         <title>     0.9484    0.9671    0.9577       456
        <volume>     0.9776    0.9850    0.9813       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9502    0.9578    0.9540      3984


------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights8.hdf5
  f1 (micro): 95.22
                  precision    recall  f1-score   support

        <author>     0.9562    0.9562    0.9562       639
     <booktitle>     0.7724    0.8051    0.7884       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9857    0.9857    0.9857       697
        <editor>     0.7143    0.7143    0.7143        14
   <institution>     0.6842    0.6842    0.6842        19
         <issue>     0.8354    0.9429    0.8859        70
       <journal>     0.9501    0.9590    0.9545       536
      <location>     0.9053    0.9149    0.9101        94
          <note>     0.7368    0.7179    0.7273        39
         <pages>     0.9810    0.9861    0.9835       576
     <publisher>     0.8364    0.9200    0.8762        50
        <pubnum>     0.9151    0.9604    0.9372       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6667    0.7059    0.6857        17
         <title>     0.9605    0.9605    0.9605       456
        <volume>     0.9666    0.9793    0.9729       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9473    0.9571    0.9522      3984


------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights9.hdf5
  f1 (micro): 95.20
                  precision    recall  f1-score   support

        <author>     0.9547    0.9562    0.9554       639
     <booktitle>     0.7521    0.7458    0.7489       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9871    0.9842    0.9856       697
        <editor>     0.6875    0.7857    0.7333        14
   <institution>     0.5909    0.6842    0.6341        19
         <issue>     0.8933    0.9571    0.9241        70
       <journal>     0.9414    0.9590    0.9501       536
      <location>     0.9158    0.9255    0.9206        94
          <note>     0.8182    0.6923    0.7500        39
         <pages>     0.9828    0.9896    0.9862       576
     <publisher>     0.9184    0.9000    0.9091        50
        <pubnum>     0.9223    0.9406    0.9314       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6000    0.7059    0.6486        17
         <title>     0.9483    0.9649    0.9565       456
        <volume>     0.9739    0.9812    0.9775       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9480    0.9561    0.9520      3984

----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

        <author>     0.9501    0.9531    0.9516       639
     <booktitle>     0.7015    0.7966    0.7460       118
 <collaboration>     0.8333    0.8333    0.8333        12
          <date>     0.9757    0.9813    0.9785       697
        <editor>     0.7143    0.7143    0.7143        14
   <institution>     0.6842    0.6842    0.6842        19
         <issue>     0.8205    0.9143    0.8649        70
       <journal>     0.9393    0.9534    0.9463       536
      <location>     0.9247    0.9149    0.9198        94
          <note>     0.6829    0.7179    0.7000        39
         <pages>     0.9775    0.9826    0.9801       576
     <publisher>     0.8679    0.9200    0.8932        50
        <pubnum>     0.9048    0.9406    0.9223       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.4800    0.7059    0.5714        17
         <title>     0.9648    0.9605    0.9626       456
        <volume>     0.9665    0.9774    0.9720       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9387    0.9533    0.9460      3984


** Best ** model scores - run 7
                  precision    recall  f1-score   support

        <author>     0.9592    0.9562    0.9577       639
     <booktitle>     0.7731    0.7797    0.7764       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9870    0.9828    0.9849       697
        <editor>     0.7333    0.7857    0.7586        14
   <institution>     0.6190    0.6842    0.6500        19
         <issue>     0.9067    0.9714    0.9379        70
       <journal>     0.9538    0.9627    0.9582       536
      <location>     0.8763    0.9043    0.8901        94
          <note>     0.7297    0.6923    0.7105        39
         <pages>     0.9810    0.9861    0.9835       576
     <publisher>     0.9184    0.9000    0.9091        50
        <pubnum>     0.9417    0.9604    0.9510       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5714    0.7059    0.6316        17
         <title>     0.9484    0.9671    0.9577       456
        <volume>     0.9776    0.9850    0.9813       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9502    0.9578    0.9540      3984

loading model weights data/models/sequenceLabelling/grobid-citation-BERT_CRF_FEATURES/model_weights7.hdf5
----------------------------------------------------------------------

Average over 2 folds
                  precision    recall  f1-score   support

        <author>     0.9559    0.9563    0.9561       639
     <booktitle>     0.7461    0.7856    0.7650       118
 <collaboration>     0.8709    0.8250    0.8467        12
          <date>     0.9853    0.9836    0.9845       697
        <editor>     0.7098    0.7643    0.7354        14
   <institution>     0.6694    0.6947    0.6809        19
         <issue>     0.8668    0.9400    0.9017        70
       <journal>     0.9495    0.9576    0.9536       536
      <location>     0.8916    0.9149    0.9030        94
          <note>     0.7043    0.7051    0.7038        39
         <pages>     0.9812    0.9851    0.9831       576
     <publisher>     0.8746    0.9060    0.8895        50
        <pubnum>     0.9306    0.9495    0.9398       101
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.5756    0.7059    0.6331        17
         <title>     0.9534    0.9623    0.9578       456
        <volume>     0.9702    0.9801    0.9751       532
           <web>     0.9115    0.9250    0.9180        12

all (micro avg.)     0.9456    0.9557    0.9506        




affiliation-address
===================

> python3 delft/applications/grobidTagger.py affiliation-address train_eval --architecture BidLSTM_CRF --embedding glove-840B --input data/sequenceLabelling/grobid/affiliation-address/affiliation-address-060518.train --fold-count 10

training runtime: 11043.265 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
    f1 (micro): 86.27
                  precision    recall  f1-score   support

      <addrLine>     0.7273    0.7742    0.7500        62
       <country>     0.9390    0.9747    0.9565       158
    <department>     0.8092    0.8333    0.8211       168
   <institution>     0.8000    0.8133    0.8066       241
    <laboratory>     0.7692    0.5714    0.6557        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.7143    0.8333    0.7692         6
      <postCode>     0.9292    0.9130    0.9211       115
        <region>     0.8333    0.8036    0.8182        56
    <settlement>     0.8854    0.8854    0.8854       192

all (micro avg.)     0.8593    0.8661    0.8627      1128


------------------------ fold 1 --------------------------------------
    f1 (micro): 86.55
                  precision    recall  f1-score   support

      <addrLine>     0.7273    0.7742    0.7500        62
       <country>     0.9506    0.9747    0.9625       158
    <department>     0.8024    0.7976    0.8000       168
   <institution>     0.8107    0.8174    0.8140       241
    <laboratory>     0.7000    0.6000    0.6462        35
        <marker>     0.9792    0.9895    0.9843        95
       <postBox>     0.7143    0.8333    0.7692         6
      <postCode>     0.9115    0.8957    0.9035       115
        <region>     0.9091    0.8929    0.9009        56
    <settlement>     0.9086    0.8802    0.8942       192

all (micro avg.)     0.8667    0.8644    0.8655      1128


------------------------ fold 2 --------------------------------------
    f1 (micro): 86.52
                  precision    recall  f1-score   support

      <addrLine>     0.7313    0.7903    0.7597        62
       <country>     0.9625    0.9747    0.9686       158
    <department>     0.8144    0.8095    0.8119       168
   <institution>     0.8033    0.8133    0.8082       241
    <laboratory>     0.6562    0.6000    0.6269        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9375    0.9130    0.9251       115
        <region>     0.8704    0.8393    0.8545        56
    <settlement>     0.8827    0.9010    0.8918       192

all (micro avg.)     0.8626    0.8679    0.8652      1128


------------------------ fold 3 --------------------------------------
    f1 (micro): 86.36
                  precision    recall  f1-score   support

      <addrLine>     0.7385    0.7742    0.7559        62
       <country>     0.9568    0.9810    0.9688       158
    <department>     0.7778    0.8333    0.8046       168
   <institution>     0.8136    0.7967    0.8050       241
    <laboratory>     0.7143    0.5714    0.6349        35
        <marker>     0.9792    0.9895    0.9843        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9292    0.9130    0.9211       115
        <region>     0.8519    0.8214    0.8364        56
    <settlement>     0.9000    0.8906    0.8953       192

all (micro avg.)     0.8628    0.8644    0.8636      1128


------------------------ fold 4 --------------------------------------
    f1 (micro): 86.38
                  precision    recall  f1-score   support

      <addrLine>     0.8033    0.7903    0.7967        62
       <country>     0.9568    0.9810    0.9688       158
    <department>     0.7566    0.8512    0.8011       168
   <institution>     0.8297    0.7884    0.8085       241
    <laboratory>     0.7037    0.5429    0.6129        35
        <marker>     0.9789    0.9789    0.9789        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9043    0.9043    0.9043       115
        <region>     0.8571    0.8571    0.8571        56
    <settlement>     0.8706    0.9115    0.8906       192

all (micro avg.)     0.8589    0.8688    0.8638      1128


------------------------ fold 5 --------------------------------------
    f1 (micro): 86.71
                  precision    recall  f1-score   support

      <addrLine>     0.7424    0.7903    0.7656        62
       <country>     0.9630    0.9873    0.9750       158
    <department>     0.8214    0.8214    0.8214       168
   <institution>     0.8201    0.8133    0.8167       241
    <laboratory>     0.6579    0.7143    0.6849        35
        <marker>     0.9592    0.9895    0.9741        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.9211    0.9130    0.9170       115
        <region>     0.9000    0.8036    0.8491        56
    <settlement>     0.8718    0.8854    0.8786       192

all (micro avg.)     0.8637    0.8706    0.8671      1128


------------------------ fold 6 --------------------------------------
    f1 (micro): 86.58
                  precision    recall  f1-score   support

      <addrLine>     0.7812    0.8065    0.7937        62
       <country>     0.9506    0.9747    0.9625       158
    <department>     0.7964    0.7917    0.7940       168
   <institution>     0.8040    0.8340    0.8187       241
    <laboratory>     0.7241    0.6000    0.6562        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.9469    0.9304    0.9386       115
        <region>     0.8148    0.7857    0.8000        56
    <settlement>     0.8872    0.9010    0.8941       192

all (micro avg.)     0.8620    0.8697    0.8658      1128


------------------------ fold 7 --------------------------------------
    f1 (micro): 87.43
                  precision    recall  f1-score   support

      <addrLine>     0.7164    0.7742    0.7442        62
       <country>     0.9627    0.9810    0.9718       158
    <department>     0.8092    0.8333    0.8211       168
   <institution>     0.8223    0.8257    0.8240       241
    <laboratory>     0.7778    0.6000    0.6774        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.7143    0.8333    0.7692         6
      <postCode>     0.9381    0.9217    0.9298       115
        <region>     0.8654    0.8036    0.8333        56
    <settlement>     0.9067    0.9115    0.9091       192

all (micro avg.)     0.8728    0.8759    0.8743      1128


------------------------ fold 8 --------------------------------------
    f1 (micro): 86.40
                  precision    recall  f1-score   support

      <addrLine>     0.7273    0.7742    0.7500        62
       <country>     0.9500    0.9620    0.9560       158
    <department>     0.8447    0.8095    0.8267       168
   <institution>     0.8008    0.8340    0.8171       241
    <laboratory>     0.5641    0.6286    0.5946        35
        <marker>     0.9792    0.9895    0.9843        95
       <postBox>     0.8333    0.8333    0.8333         6
      <postCode>     0.9043    0.9043    0.9043       115
        <region>     0.8727    0.8571    0.8649        56
    <settlement>     0.9167    0.8594    0.8871       192

all (micro avg.)     0.8636    0.8644    0.8640      1128


------------------------ fold 9 --------------------------------------
    f1 (micro): 86.19
                  precision    recall  f1-score   support

      <addrLine>     0.7121    0.7581    0.7344        62
       <country>     0.9627    0.9810    0.9718       158
    <department>     0.7955    0.8333    0.8140       168
   <institution>     0.7992    0.8091    0.8041       241
    <laboratory>     0.6207    0.5143    0.5625        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9130    0.9130    0.9130       115
        <region>     0.8909    0.8750    0.8829        56
    <settlement>     0.8782    0.9010    0.8895       192

all (micro avg.)     0.8551    0.8688    0.8619      1128

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

      <addrLine>     0.7121    0.7581    0.7344        62
       <country>     0.9627    0.9810    0.9718       158
    <department>     0.7955    0.8333    0.8140       168
   <institution>     0.7992    0.8091    0.8041       241
    <laboratory>     0.6207    0.5143    0.5625        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9130    0.9130    0.9130       115
        <region>     0.8909    0.8750    0.8829        56
    <settlement>     0.8782    0.9010    0.8895       192

all (micro avg.)     0.8551    0.8688    0.8619      1128


** Best ** model scores - run 7
                  precision    recall  f1-score   support

      <addrLine>     0.7164    0.7742    0.7442        62
       <country>     0.9627    0.9810    0.9718       158
    <department>     0.8092    0.8333    0.8211       168
   <institution>     0.8223    0.8257    0.8240       241
    <laboratory>     0.7778    0.6000    0.6774        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.7143    0.8333    0.7692         6
      <postCode>     0.9381    0.9217    0.9298       115
        <region>     0.8654    0.8036    0.8333        56
    <settlement>     0.9067    0.9115    0.9091       192

all (micro avg.)     0.8728    0.8759    0.8743      1128

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

      <addrLine>     0.7407    0.7806    0.7600        62
       <country>     0.9555    0.9772    0.9662       158
    <department>     0.8028    0.8214    0.8116       168
   <institution>     0.8104    0.8145    0.8123       241
    <laboratory>     0.6888    0.5943    0.6352        35
        <marker>     0.9721    0.9884    0.9802        95
       <postBox>     0.6786    0.7333    0.7038         6
      <postCode>     0.9235    0.9122    0.9178       115
        <region>     0.8666    0.8339    0.8497        56
    <settlement>     0.8908    0.8927    0.8915       192

all (micro avg.)     0.8627    0.8681    0.8654 


> python3 delft/applications/grobidTagger.py affiliation-address train_eval --architecture BidLSTM_CRF_FEATURES --embedding glove-840B --input data/sequenceLabelling/grobid/affiliation-address/affiliation-address-060518.train --fold-count 10

training runtime: 12045.537 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
    f1 (micro): 87.35
                  precision    recall  f1-score   support

      <addrLine>     0.7742    0.7742    0.7742        62
       <country>     0.9752    0.9937    0.9843       158
    <department>     0.8084    0.8036    0.8060       168
   <institution>     0.8223    0.8257    0.8240       241
    <laboratory>     0.6389    0.6571    0.6479        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.8333    0.8333    0.8333         6
      <postCode>     0.9211    0.9130    0.9170       115
        <region>     0.8889    0.8571    0.8727        56
    <settlement>     0.8964    0.9010    0.8987       192

all (micro avg.)     0.8719    0.8750    0.8735      1128


------------------------ fold 1 --------------------------------------
    f1 (micro): 85.84
                  precision    recall  f1-score   support

      <addrLine>     0.7581    0.7581    0.7581        62
       <country>     0.9568    0.9810    0.9688       158
    <department>     0.8250    0.7857    0.8049       168
   <institution>     0.8017    0.8050    0.8033       241
    <laboratory>     0.5333    0.6857    0.6000        35
        <marker>     0.9688    0.9789    0.9738        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.8879    0.8957    0.8918       115
        <region>     0.8621    0.8929    0.8772        56
    <settlement>     0.9130    0.8750    0.8936       192

all (micro avg.)     0.8569    0.8599    0.8584      1128


------------------------ fold 2 --------------------------------------
    f1 (micro): 87.81
                  precision    recall  f1-score   support

      <addrLine>     0.7500    0.7742    0.7619        62
       <country>     0.9627    0.9810    0.9718       158
    <department>     0.7989    0.8512    0.8242       168
   <institution>     0.8397    0.8257    0.8326       241
    <laboratory>     0.7931    0.6571    0.7188        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9292    0.9130    0.9211       115
        <region>     0.8947    0.9107    0.9027        56
    <settlement>     0.8912    0.8958    0.8935       192

all (micro avg.)     0.8750    0.8812    0.8781      1128


------------------------ fold 3 --------------------------------------
    f1 (micro): 87.21
                  precision    recall  f1-score   support

      <addrLine>     0.7188    0.7419    0.7302        62
       <country>     0.9506    0.9747    0.9625       158
    <department>     0.8161    0.8452    0.8304       168
   <institution>     0.8382    0.8382    0.8382       241
    <laboratory>     0.6364    0.6000    0.6176        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9286    0.9043    0.9163       115
        <region>     0.8704    0.8393    0.8545        56
    <settlement>     0.9096    0.8906    0.9000       192

all (micro avg.)     0.8709    0.8732    0.8721      1128


------------------------ fold 4 --------------------------------------
    f1 (micro): 86.58
                  precision    recall  f1-score   support

      <addrLine>     0.7377    0.7258    0.7317        62
       <country>     0.9500    0.9620    0.9560       158
    <department>     0.8057    0.8393    0.8222       168
   <institution>     0.8235    0.8133    0.8184       241
    <laboratory>     0.6667    0.6286    0.6471        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9115    0.8957    0.9035       115
        <region>     0.8889    0.8571    0.8727        56
    <settlement>     0.8958    0.8958    0.8958       192

all (micro avg.)     0.8654    0.8661    0.8658      1128


------------------------ fold 5 --------------------------------------
    f1 (micro): 86.38
                  precision    recall  f1-score   support

      <addrLine>     0.7778    0.7903    0.7840        62
       <country>     0.9568    0.9810    0.9688       158
    <department>     0.8012    0.7917    0.7964       168
   <institution>     0.8082    0.8216    0.8148       241
    <laboratory>     0.6129    0.5429    0.5758        35
        <marker>     0.9688    0.9789    0.9738        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.9123    0.9043    0.9083       115
        <region>     0.8167    0.8750    0.8448        56
    <settlement>     0.9105    0.9010    0.9058       192

all (micro avg.)     0.8616    0.8661    0.8638      1128


------------------------ fold 6 --------------------------------------
    f1 (micro): 86.55
                  precision    recall  f1-score   support

      <addrLine>     0.7500    0.7742    0.7619        62
       <country>     0.9625    0.9747    0.9686       158
    <department>     0.8160    0.7917    0.8036       168
   <institution>     0.7968    0.8299    0.8130       241
    <laboratory>     0.6667    0.6286    0.6471        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.9469    0.9304    0.9386       115
        <region>     0.8491    0.8036    0.8257        56
    <settlement>     0.8953    0.8906    0.8930       192

all (micro avg.)     0.8640    0.8670    0.8655      1128


------------------------ fold 7 --------------------------------------
    f1 (micro): 86.83
                  precision    recall  f1-score   support

      <addrLine>     0.7424    0.7903    0.7656        62
       <country>     0.9503    0.9684    0.9592       158
    <department>     0.8000    0.8333    0.8163       168
   <institution>     0.8216    0.8216    0.8216       241
    <laboratory>     0.6286    0.6286    0.6286        35
        <marker>     0.9792    0.9895    0.9843        95
       <postBox>     0.8333    0.8333    0.8333         6
      <postCode>     0.9204    0.9043    0.9123       115
        <region>     0.9020    0.8214    0.8598        56
    <settlement>     0.9000    0.8906    0.8953       192

all (micro avg.)     0.8660    0.8706    0.8683      1128


------------------------ fold 8 --------------------------------------
    f1 (micro): 85.89
                  precision    recall  f1-score   support

      <addrLine>     0.7385    0.7742    0.7559        62
       <country>     0.9565    0.9747    0.9655       158
    <department>     0.7964    0.7917    0.7940       168
   <institution>     0.7958    0.7925    0.7942       241
    <laboratory>     0.6316    0.6857    0.6575        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.9545    0.9130    0.9333       115
        <region>     0.8276    0.8571    0.8421        56
    <settlement>     0.8782    0.9010    0.8895       192

all (micro avg.)     0.8544    0.8635    0.8589      1128


------------------------ fold 9 --------------------------------------
    f1 (micro): 85.92
                  precision    recall  f1-score   support

      <addrLine>     0.7619    0.7742    0.7680        62
       <country>     0.9506    0.9747    0.9625       158
    <department>     0.7879    0.7738    0.7808       168
   <institution>     0.8000    0.8133    0.8066       241
    <laboratory>     0.6316    0.6857    0.6575        35
        <marker>     0.9688    0.9789    0.9738        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.9211    0.9130    0.9170       115
        <region>     0.8571    0.8571    0.8571        56
    <settlement>     0.8953    0.8906    0.8930       192

all (micro avg.)     0.8558    0.8626    0.8592      1128

----------------------------------------------------------------------

** Worst ** model scores - run 1
                  precision    recall  f1-score   support

      <addrLine>     0.7581    0.7581    0.7581        62
       <country>     0.9568    0.9810    0.9688       158
    <department>     0.8250    0.7857    0.8049       168
   <institution>     0.8017    0.8050    0.8033       241
    <laboratory>     0.5333    0.6857    0.6000        35
        <marker>     0.9688    0.9789    0.9738        95
       <postBox>     0.5714    0.6667    0.6154         6
      <postCode>     0.8879    0.8957    0.8918       115
        <region>     0.8621    0.8929    0.8772        56
    <settlement>     0.9130    0.8750    0.8936       192

all (micro avg.)     0.8569    0.8599    0.8584      1128


** Best ** model scores - run 2
                  precision    recall  f1-score   support

      <addrLine>     0.7500    0.7742    0.7619        62
       <country>     0.9627    0.9810    0.9718       158
    <department>     0.7989    0.8512    0.8242       168
   <institution>     0.8397    0.8257    0.8326       241
    <laboratory>     0.7931    0.6571    0.7188        35
        <marker>     0.9691    0.9895    0.9792        95
       <postBox>     0.6667    0.6667    0.6667         6
      <postCode>     0.9292    0.9130    0.9211       115
        <region>     0.8947    0.9107    0.9027        56
    <settlement>     0.8912    0.8958    0.8935       192

all (micro avg.)     0.8750    0.8812    0.8781      1128

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

      <addrLine>     0.7509    0.7677    0.7591        62
       <country>     0.9572    0.9766    0.9668       158
    <department>     0.8056    0.8107    0.8079       168
   <institution>     0.8148    0.8187    0.8167       241
    <laboratory>     0.6440    0.6400    0.6398        35
        <marker>     0.9700    0.9863    0.9781        95
       <postBox>     0.6524    0.7000    0.6744         6
      <postCode>     0.9233    0.9087    0.9159       115
        <region>     0.8657    0.8571    0.8609        56
    <settlement>     0.8985    0.8932    0.8958       192

all (micro avg.)     0.8642    0.8685    0.8663 



header
======

> python3 delft/applications/grobidTagger.py header train_eval --architecture BERT_CRF --transformer allenai/scibert_scivocab_cased --input data/sequenceLabelling/grobid/header/header-050721.train --fold-count 10


training runtime: 20510.672 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights0.hdf5
  f1 (micro): 78.83
                  precision    recall  f1-score   support

      <abstract>     0.7324    0.8254    0.7761        63
       <address>     0.7654    0.8267    0.7949       150
   <affiliation>     0.7640    0.8193    0.7907       166
        <author>     0.7706    0.8155    0.7925       103
     <copyright>     0.7200    0.8182    0.7660        22
          <date>     0.9643    0.9643    0.9643        28
       <doctype>     0.7692    0.8333    0.8000        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9375    0.9524    0.9449        63
       <funding>     0.0769    0.2000    0.1111         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7419    0.8519    0.7931        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.5385    0.7500    0.6269        28
    <submission>     0.6522    0.8333    0.7317        18
         <title>     0.7532    0.8657    0.8056        67
           <web>     0.5000    0.5000    0.5000         2

all (micro avg.)     0.7509    0.8297    0.7883       781


------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights1.hdf5
  f1 (micro): 78.01
                  precision    recall  f1-score   support

      <abstract>     0.7324    0.8254    0.7761        63
       <address>     0.7640    0.8200    0.7910       150
   <affiliation>     0.7348    0.8012    0.7666       166
        <author>     0.7217    0.8058    0.7615       103
     <copyright>     0.6800    0.7727    0.7234        22
          <date>     0.9643    0.9643    0.9643        28
       <doctype>     0.8333    0.8333    0.8333        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9375    0.9524    0.9449        63
       <funding>     0.0000    0.0000    0.0000         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7742    0.8889    0.8276        27
       <meeting>     0.6667    0.5000    0.5714         4
        <pubnum>     0.6957    0.8000    0.7442        20
     <reference>     0.5641    0.7857    0.6567        28
    <submission>     0.6250    0.8333    0.7143        18
         <title>     0.7733    0.8657    0.8169        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7402    0.8246    0.7801       781


------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights2.hdf5
  f1 (micro): 76.19
                  precision    recall  f1-score   support

      <abstract>     0.7429    0.8254    0.7820        63
       <address>     0.7560    0.8467    0.7987       150
   <affiliation>     0.7021    0.7952    0.7458       166
        <author>     0.7025    0.8252    0.7589       103
     <copyright>     0.5806    0.8182    0.6792        22
          <date>     0.8929    0.8929    0.8929        28
       <doctype>     0.6154    0.6667    0.6400        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9219    0.9365    0.9291        63
       <funding>     0.0625    0.2000    0.0952         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7059    0.8889    0.7869        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.6667    0.8000    0.7273        20
     <reference>     0.5588    0.6786    0.6129        28
    <submission>     0.5185    0.7778    0.6222        18
         <title>     0.7568    0.8358    0.7943        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7119    0.8195    0.7619       781


------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights3.hdf5
  f1 (micro): 77.74
                  precision    recall  f1-score   support

      <abstract>     0.7500    0.8571    0.8000        63
       <address>     0.7812    0.8333    0.8065       150
   <affiliation>     0.7351    0.8193    0.7749       166
        <author>     0.7155    0.8058    0.7580       103
     <copyright>     0.7826    0.8182    0.8000        22
          <date>     0.9286    0.9286    0.9286        28
       <doctype>     0.8333    0.8333    0.8333        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9365    0.9365    0.9365        63
       <funding>     0.0000    0.0000    0.0000         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7742    0.8889    0.8276        27
       <meeting>     0.4000    0.5000    0.4444         4
        <pubnum>     0.6400    0.8000    0.7111        20
     <reference>     0.5714    0.7143    0.6349        28
    <submission>     0.5769    0.8333    0.6818        18
         <title>     0.7703    0.8507    0.8085        67
           <web>     0.3333    0.5000    0.4000         2

all (micro avg.)     0.7333    0.8271    0.7774       781


------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights4.hdf5
  f1 (micro): 78.08
                  precision    recall  f1-score   support

      <abstract>     0.7794    0.8413    0.8092        63
       <address>     0.7469    0.8067    0.7756       150
   <affiliation>     0.7486    0.8072    0.7768       166
        <author>     0.7167    0.8350    0.7713       103
     <copyright>     0.7037    0.8636    0.7755        22
          <date>     0.9286    0.9286    0.9286        28
       <doctype>     0.9167    0.9167    0.9167        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9375    0.9524    0.9449        63
       <funding>     0.0370    0.2000    0.0625         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.9259    0.9259    0.9259        27
       <meeting>     0.2500    0.5000    0.3333         4
        <pubnum>     0.7619    0.8000    0.7805        20
     <reference>     0.5263    0.7143    0.6061        28
    <submission>     0.6000    0.8333    0.6977        18
         <title>     0.7973    0.8806    0.8369        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7353    0.8323    0.7808       781


------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights5.hdf5
  f1 (micro): 77.49
                  precision    recall  f1-score   support

      <abstract>     0.6709    0.8413    0.7465        63
       <address>     0.8025    0.8400    0.8208       150
   <affiliation>     0.7701    0.8072    0.7882       166
        <author>     0.7034    0.8058    0.7511       103
     <copyright>     0.7600    0.8636    0.8085        22
          <date>     0.9286    0.9286    0.9286        28
       <doctype>     0.7692    0.8333    0.8000        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9365    0.9365    0.9365        63
       <funding>     0.0357    0.2000    0.0606         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7273    0.8889    0.8000        27
       <meeting>     0.3333    0.5000    0.4000         4
        <pubnum>     0.6400    0.8000    0.7111        20
     <reference>     0.5385    0.7500    0.6269        28
    <submission>     0.6818    0.8333    0.7500        18
         <title>     0.7342    0.8657    0.7945        67
           <web>     0.5000    1.0000    0.6667         2

all (micro avg.)     0.7260    0.8310    0.7749       781


------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights6.hdf5
  f1 (micro): 79.27
                  precision    recall  f1-score   support

      <abstract>     0.7500    0.8095    0.7786        63
       <address>     0.7744    0.8467    0.8089       150
   <affiliation>     0.7486    0.8253    0.7851       166
        <author>     0.7685    0.8058    0.7867       103
     <copyright>     0.6923    0.8182    0.7500        22
          <date>     0.9286    0.9286    0.9286        28
       <doctype>     0.7500    0.7500    0.7500        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9531    0.9683    0.9606        63
       <funding>     0.0556    0.2000    0.0870         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7742    0.8889    0.8276        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.6000    0.7500    0.6667        28
    <submission>     0.6250    0.8333    0.7143        18
         <title>     0.7973    0.8806    0.8369        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7546    0.8348    0.7927       781


------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights7.hdf5
  f1 (micro): 79.29
                  precision    recall  f1-score   support

      <abstract>     0.7536    0.8254    0.7879        63
       <address>     0.7826    0.8400    0.8103       150
   <affiliation>     0.7432    0.8193    0.7794       166
        <author>     0.7963    0.8350    0.8152       103
     <copyright>     0.7500    0.8182    0.7826        22
          <date>     0.9259    0.8929    0.9091        28
       <doctype>     0.7500    0.7500    0.7500        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9375    0.9524    0.9449        63
       <funding>     0.0556    0.2000    0.0870         5
         <group>     1.0000    0.5000    0.6667         2
       <keyword>     0.8065    0.9259    0.8621        27
       <meeting>     0.5000    0.7500    0.6000         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.5429    0.6786    0.6032        28
    <submission>     0.6364    0.7778    0.7000        18
         <title>     0.7632    0.8657    0.8112        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7561    0.8335    0.7929       781


------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights8.hdf5
  f1 (micro): 77.68
                  precision    recall  f1-score   support

      <abstract>     0.7681    0.8413    0.8030        63
       <address>     0.7805    0.8533    0.8153       150
   <affiliation>     0.7181    0.8133    0.7627       166
        <author>     0.7391    0.8252    0.7798       103
     <copyright>     0.7308    0.8636    0.7917        22
          <date>     0.8929    0.8929    0.8929        28
       <doctype>     0.6923    0.7500    0.7200        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8955    0.9524    0.9231        63
       <funding>     0.0870    0.4000    0.1429         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8000    0.8889    0.8421        27
       <meeting>     0.2500    0.5000    0.3333         4
        <pubnum>     0.6522    0.7500    0.6977        20
     <reference>     0.5263    0.7143    0.6061        28
    <submission>     0.6250    0.8333    0.7143        18
         <title>     0.7703    0.8507    0.8085        67
           <web>     0.5000    1.0000    0.6667         2

all (micro avg.)     0.7274    0.8335    0.7768       781


------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights9.hdf5
  f1 (micro): 78.67
                  precision    recall  f1-score   support

      <abstract>     0.7432    0.8730    0.8029        63
       <address>     0.7531    0.8133    0.7821       150
   <affiliation>     0.7204    0.8072    0.7614       166
        <author>     0.7368    0.8155    0.7742       103
     <copyright>     0.7692    0.9091    0.8333        22
          <date>     0.9643    0.9643    0.9643        28
       <doctype>     0.8462    0.9167    0.8800        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9091    0.9524    0.9302        63
       <funding>     0.0714    0.2000    0.1053         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7500    0.8889    0.8136        27
       <meeting>     0.4000    0.5000    0.4444         4
        <pubnum>     0.6957    0.8000    0.7442        20
     <reference>     0.6176    0.7500    0.6774        28
    <submission>     0.6087    0.7778    0.6829        18
         <title>     0.8108    0.8955    0.8511        67
           <web>     0.5000    1.0000    0.6667         2

all (micro avg.)     0.7429    0.8361    0.7867       781

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

      <abstract>     0.7429    0.8254    0.7820        63
       <address>     0.7560    0.8467    0.7987       150
   <affiliation>     0.7021    0.7952    0.7458       166
        <author>     0.7025    0.8252    0.7589       103
     <copyright>     0.5806    0.8182    0.6792        22
          <date>     0.8929    0.8929    0.8929        28
       <doctype>     0.6154    0.6667    0.6400        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9219    0.9365    0.9291        63
       <funding>     0.0625    0.2000    0.0952         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7059    0.8889    0.7869        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.6667    0.8000    0.7273        20
     <reference>     0.5588    0.6786    0.6129        28
    <submission>     0.5185    0.7778    0.6222        18
         <title>     0.7568    0.8358    0.7943        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7119    0.8195    0.7619       781


** Best ** model scores - run 7
                  precision    recall  f1-score   support

      <abstract>     0.7536    0.8254    0.7879        63
       <address>     0.7826    0.8400    0.8103       150
   <affiliation>     0.7432    0.8193    0.7794       166
        <author>     0.7963    0.8350    0.8152       103
     <copyright>     0.7500    0.8182    0.7826        22
          <date>     0.9259    0.8929    0.9091        28
       <doctype>     0.7500    0.7500    0.7500        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9375    0.9524    0.9449        63
       <funding>     0.0556    0.2000    0.0870         5
         <group>     1.0000    0.5000    0.6667         2
       <keyword>     0.8065    0.9259    0.8621        27
       <meeting>     0.5000    0.7500    0.6000         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.5429    0.6786    0.6032        28
    <submission>     0.6364    0.7778    0.7000        18
         <title>     0.7632    0.8657    0.8112        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7561    0.8335    0.7929       781

loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF/model_weights7.hdf5
----------------------------------------------------------------------

Average over 2 folds
                  precision    recall  f1-score   support

      <abstract>     0.7423    0.8365    0.7862        63
       <address>     0.7707    0.8327    0.8004       150
   <affiliation>     0.7385    0.8114    0.7732       166
        <author>     0.7371    0.8175    0.7749       103
     <copyright>     0.7169    0.8364    0.7710        22
          <date>     0.9319    0.9286    0.9302        28
       <doctype>     0.7776    0.8083    0.7923        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9303    0.9492    0.9396        63
       <funding>     0.0482    0.1800    0.0751         5
         <group>     0.1000    0.0500    0.0667         2
       <keyword>     0.7780    0.8926    0.8306        27
       <meeting>     0.4300    0.5250    0.4627         4
        <pubnum>     0.6934    0.7950    0.7402        20
     <reference>     0.5584    0.7286    0.6318        28
    <submission>     0.6149    0.8167    0.7009        18
         <title>     0.7727    0.8657    0.8164        67
           <web>     0.7333    0.9000    0.7900         2

all (micro avg.)     0.7378    0.8302    0.7813  


> python3 delft/applications/grobidTagger.py header train_eval --architecture BERT_CRF_FEATURES --transformer allenai/scibert_scivocab_cased --input data/sequenceLabelling/grobid/header/header-050721.train --fold-count 10


training runtime: 83413.97 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights0.hdf5
  f1 (micro): 79.61
                  precision    recall  f1-score   support

      <abstract>     0.7606    0.8571    0.8060        63
       <address>     0.7848    0.8267    0.8052       150
   <affiliation>     0.7418    0.8133    0.7759       166
        <author>     0.6930    0.7670    0.7281       103
     <copyright>     0.8333    0.9091    0.8696        22
          <date>     0.9643    0.9643    0.9643        28
       <doctype>     1.0000    0.8333    0.9091        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8923    0.9206    0.9062        63
       <funding>     0.2000    0.4000    0.2667         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8621    0.9259    0.8929        27
       <meeting>     1.0000    0.7500    0.8571         4
        <pubnum>     0.7619    0.8000    0.7805        20
     <reference>     0.6562    0.7500    0.7000        28
    <submission>     0.6957    0.8889    0.7805        18
         <title>     0.7468    0.8806    0.8082        67
           <web>     0.3333    0.5000    0.4000         2

all (micro avg.)     0.7629    0.8323    0.7961       781


------------------------ fold 1 --------------------------------------
__________________________________________________________________________________________________
Model: "crf_model_wrapper_for_bert_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 crf_11 (CRF)                multiple                  5358      
                                                                 
 model_11 (Functional)       (None, None, 100)         110661480 
                                                                 
=================================================================
Total params: 110,666,838
Trainable params: 110,665,778
Non-trainable params: 1,060
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights1.hdf5
  f1 (micro): 76.72
                  precision    recall  f1-score   support

      <abstract>     0.7162    0.8413    0.7737        63
       <address>     0.7365    0.8200    0.7760       150
   <affiliation>     0.6878    0.7831    0.7324       166
        <author>     0.7018    0.7767    0.7373       103
     <copyright>     0.7083    0.7727    0.7391        22
          <date>     0.8966    0.9286    0.9123        28
       <doctype>     0.3000    0.2500    0.2727        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9524    0.9524    0.9524        63
       <funding>     0.1818    0.4000    0.2500         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8276    0.8889    0.8571        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.7000    0.7500    0.7241        28
    <submission>     0.7143    0.8333    0.7692        18
         <title>     0.7808    0.8507    0.8143        67
           <web>     0.6667    1.0000    0.8000         2

all (micro avg.)     0.7303    0.8079    0.7672       781


------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights2.hdf5
  f1 (micro): 78.92
                  precision    recall  f1-score   support

      <abstract>     0.7013    0.8571    0.7714        63
       <address>     0.7750    0.8267    0.8000       150
   <affiliation>     0.7418    0.8133    0.7759       166
        <author>     0.7241    0.8155    0.7671       103
     <copyright>     0.7083    0.7727    0.7391        22
          <date>     1.0000    0.9643    0.9818        28
       <doctype>     0.5556    0.4167    0.4762        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9077    0.9365    0.9219        63
       <funding>     0.2500    0.4000    0.3077         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8214    0.8519    0.8364        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.6774    0.7500    0.7119        28
    <submission>     0.6957    0.8889    0.7805        18
         <title>     0.7917    0.8507    0.8201        67
           <web>     0.6667    1.0000    0.8000         2

all (micro avg.)     0.7568    0.8246    0.7892       781


------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights3.hdf5
  f1 (micro): 76.90
                  precision    recall  f1-score   support

      <abstract>     0.6667    0.8571    0.7500        63
       <address>     0.7949    0.8267    0.8105       150
   <affiliation>     0.7074    0.8012    0.7514       166
        <author>     0.6810    0.7670    0.7215       103
     <copyright>     0.6800    0.7727    0.7234        22
          <date>     0.9231    0.8571    0.8889        28
       <doctype>     0.2000    0.1667    0.1818        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8529    0.9206    0.8855        63
       <funding>     0.0769    0.2000    0.1111         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8462    0.8148    0.8302        27
       <meeting>     0.6667    0.5000    0.5714         4
        <pubnum>     0.8571    0.9000    0.8780        20
     <reference>     0.7097    0.7857    0.7458        28
    <submission>     0.7143    0.8333    0.7692        18
         <title>     0.8082    0.8806    0.8429        67
           <web>     0.5000    0.5000    0.5000         2

all (micro avg.)     0.7337    0.8079    0.7690       781


------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights4.hdf5
  f1 (micro): 75.78
                  precision    recall  f1-score   support

      <abstract>     0.7222    0.8254    0.7704        63
       <address>     0.7702    0.8267    0.7974       150
   <affiliation>     0.7293    0.7952    0.7608       166
        <author>     0.6807    0.7864    0.7297       103
     <copyright>     0.7826    0.8182    0.8000        22
          <date>     0.8571    0.8571    0.8571        28
       <doctype>     0.3333    0.1667    0.2222        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8806    0.9365    0.9077        63
       <funding>     0.0909    0.2000    0.1250         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.6970    0.8519    0.7667        27
       <meeting>     0.3333    0.2500    0.2857         4
        <pubnum>     0.8095    0.8500    0.8293        20
     <reference>     0.6452    0.7143    0.6780        28
    <submission>     0.5909    0.7222    0.6500        18
         <title>     0.6795    0.7910    0.7310        67
           <web>     0.5000    0.5000    0.5000         2

all (micro avg.)     0.7238    0.7951    0.7578       781


------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights5.hdf5
  f1 (micro): 79.36
                  precision    recall  f1-score   support

      <abstract>     0.7606    0.8571    0.8060        63
       <address>     0.8117    0.8333    0.8224       150
   <affiliation>     0.7348    0.8012    0.7666       166
        <author>     0.7387    0.7961    0.7664       103
     <copyright>     0.7917    0.8636    0.8261        22
          <date>     0.9310    0.9643    0.9474        28
       <doctype>     0.7143    0.4167    0.5263        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9375    0.9524    0.9449        63
       <funding>     0.0833    0.2000    0.1176         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.7931    0.8519    0.8214        27
       <meeting>     1.0000    0.7500    0.8571         4
        <pubnum>     0.7826    0.9000    0.8372        20
     <reference>     0.5526    0.7500    0.6364        28
    <submission>     0.6250    0.8333    0.7143        18
         <title>     0.7838    0.8657    0.8227        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7627    0.8271    0.7936       781


------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights6.hdf5
  f1 (micro): 79.36
                  precision    recall  f1-score   support

      <abstract>     0.7857    0.8730    0.8271        63
       <address>     0.7937    0.8467    0.8194       150
   <affiliation>     0.7253    0.7952    0.7586       166
        <author>     0.6723    0.7767    0.7207       103
     <copyright>     0.9048    0.8636    0.8837        22
          <date>     0.9630    0.9286    0.9455        28
       <doctype>     0.4000    0.1667    0.2353        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9524    0.9524    0.9524        63
       <funding>     0.0000    0.0000    0.0000         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8929    0.9259    0.9091        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.7619    0.8000    0.7805        20
     <reference>     0.6364    0.7500    0.6885        28
    <submission>     0.7273    0.8889    0.8000        18
         <title>     0.8696    0.8955    0.8824        67
           <web>     0.3333    0.5000    0.4000         2

all (micro avg.)     0.7670    0.8220    0.7936       781


------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights7.hdf5
  f1 (micro): 77.93
                  precision    recall  f1-score   support

      <abstract>     0.7067    0.8413    0.7681        63
       <address>     0.7888    0.8467    0.8167       150
   <affiliation>     0.6898    0.7771    0.7309       166
        <author>     0.7009    0.7961    0.7455       103
     <copyright>     0.7200    0.8182    0.7660        22
          <date>     0.9630    0.9286    0.9455        28
       <doctype>     0.4286    0.2500    0.3158        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9524    0.9524    0.9524        63
       <funding>     0.2000    0.4000    0.2667         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.9231    0.8889    0.9057        27
       <meeting>     0.5000    0.5000    0.5000         4
        <pubnum>     0.7727    0.8500    0.8095        20
     <reference>     0.6286    0.7857    0.6984        28
    <submission>     0.6667    0.8889    0.7619        18
         <title>     0.7568    0.8358    0.7943        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7439    0.8182    0.7793       781


------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights8.hdf5
  f1 (micro): 77.41
                  precision    recall  f1-score   support

      <abstract>     0.7639    0.8730    0.8148        63
       <address>     0.7453    0.8000    0.7717       150
   <affiliation>     0.7033    0.7711    0.7356       166
        <author>     0.6897    0.7767    0.7306       103
     <copyright>     0.7500    0.8182    0.7826        22
          <date>     1.0000    0.9643    0.9818        28
       <doctype>     0.4286    0.2500    0.3158        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9206    0.9206    0.9206        63
       <funding>     0.0909    0.2000    0.1250         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8929    0.9259    0.9091        27
       <meeting>     0.6000    0.7500    0.6667         4
        <pubnum>     0.8095    0.8500    0.8293        20
     <reference>     0.6286    0.7857    0.6984        28
    <submission>     0.6400    0.8889    0.7442        18
         <title>     0.7867    0.8806    0.8310        67
           <web>     0.6667    1.0000    0.8000         2

all (micro avg.)     0.7398    0.8118    0.7741       781


------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights9.hdf5
  f1 (micro): 77.43
                  precision    recall  f1-score   support

      <abstract>     0.7746    0.8730    0.8209        63
       <address>     0.7812    0.8333    0.8065       150
   <affiliation>     0.6915    0.7831    0.7345       166
        <author>     0.6810    0.7670    0.7215       103
     <copyright>     0.8696    0.9091    0.8889        22
          <date>     0.9643    0.9643    0.9643        28
       <doctype>     0.5556    0.4167    0.4762        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8923    0.9206    0.9062        63
       <funding>     0.2000    0.4000    0.2667         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8571    0.8889    0.8727        27
       <meeting>     0.6667    0.5000    0.5714         4
        <pubnum>     0.7273    0.8000    0.7619        20
     <reference>     0.6111    0.7857    0.6875        28
    <submission>     0.5769    0.8333    0.6818        18
         <title>     0.7089    0.8358    0.7671        67
           <web>     1.0000    1.0000    1.0000         2

all (micro avg.)     0.7359    0.8169    0.7743       781

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

      <abstract>     0.7222    0.8254    0.7704        63
       <address>     0.7702    0.8267    0.7974       150
   <affiliation>     0.7293    0.7952    0.7608       166
        <author>     0.6807    0.7864    0.7297       103
     <copyright>     0.7826    0.8182    0.8000        22
          <date>     0.8571    0.8571    0.8571        28
       <doctype>     0.3333    0.1667    0.2222        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8806    0.9365    0.9077        63
       <funding>     0.0909    0.2000    0.1250         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.6970    0.8519    0.7667        27
       <meeting>     0.3333    0.2500    0.2857         4
        <pubnum>     0.8095    0.8500    0.8293        20
     <reference>     0.6452    0.7143    0.6780        28
    <submission>     0.5909    0.7222    0.6500        18
         <title>     0.6795    0.7910    0.7310        67
           <web>     0.5000    0.5000    0.5000         2

all (micro avg.)     0.7238    0.7951    0.7578       781


** Best ** model scores - run 0
                  precision    recall  f1-score   support

      <abstract>     0.7606    0.8571    0.8060        63
       <address>     0.7848    0.8267    0.8052       150
   <affiliation>     0.7418    0.8133    0.7759       166
        <author>     0.6930    0.7670    0.7281       103
     <copyright>     0.8333    0.9091    0.8696        22
          <date>     0.9643    0.9643    0.9643        28
       <doctype>     1.0000    0.8333    0.9091        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.8923    0.9206    0.9062        63
       <funding>     0.2000    0.4000    0.2667         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8621    0.9259    0.8929        27
       <meeting>     1.0000    0.7500    0.8571         4
        <pubnum>     0.7619    0.8000    0.7805        20
     <reference>     0.6562    0.7500    0.7000        28
    <submission>     0.6957    0.8889    0.7805        18
         <title>     0.7468    0.8806    0.8082        67
           <web>     0.3333    0.5000    0.4000         2

all (micro avg.)     0.7629    0.8323    0.7961       781

loading model weights data/models/sequenceLabelling/grobid-header-BERT_CRF_FEATURES/model_weights0.hdf5
----------------------------------------------------------------------

Average over 2 folds
                  precision    recall  f1-score   support

      <abstract>     0.7358    0.8556    0.7908        63
       <address>     0.7782    0.8287    0.8026       150
   <affiliation>     0.7153    0.7934    0.7523       166
        <author>     0.6963    0.7825    0.7368       103
     <copyright>     0.7749    0.8318    0.8018        22
          <date>     0.9462    0.9321    0.9389        28
       <doctype>     0.4916    0.3333    0.3931        12
        <editor>     0.0000    0.0000    0.0000         1
         <email>     0.9141    0.9365    0.9250        63
       <funding>     0.1374    0.2800    0.1836         5
         <group>     0.0000    0.0000    0.0000         2
       <keyword>     0.8413    0.8815    0.8601        27
       <meeting>     0.6267    0.5500    0.5810         4
        <pubnum>     0.7737    0.8350    0.8030        20
     <reference>     0.6446    0.7607    0.6969        28
    <submission>     0.6647    0.8500    0.7452        18
         <title>     0.7713    0.8567    0.8114        67
           <web>     0.6667    0.8000    0.7200         2

all (micro avg.)     0.7457    0.8164    0.7794    
