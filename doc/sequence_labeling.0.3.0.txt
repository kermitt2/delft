> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM --embedding glove-840B --fold-count 10

training runtime: 33753.225 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.04
                  precision    recall  f1-score   support

             LOC     0.9103    0.9311    0.9206      1668
            MISC     0.7730    0.8006    0.7866       702
             ORG     0.8603    0.8826    0.8713      1661
             PER     0.9569    0.9623    0.9596      1617

all (micro avg.)     0.8914    0.9095    0.9004      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.60
                  precision    recall  f1-score   support

             LOC     0.9098    0.9317    0.9206      1668
            MISC     0.7664    0.7806    0.7735       702
             ORG     0.8462    0.8880    0.8666      1661
             PER     0.9504    0.9592    0.9548      1617

all (micro avg.)     0.8844    0.9079    0.8960      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.77
                  precision    recall  f1-score   support

             LOC     0.9179    0.9251    0.9215      1668
            MISC     0.7878    0.7934    0.7906       702
             ORG     0.8468    0.8820    0.8641      1661
             PER     0.9526    0.9573    0.9550      1617

all (micro avg.)     0.8903    0.9053    0.8977      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 89.63
                  precision    recall  f1-score   support

             LOC     0.9037    0.9281    0.9157      1668
            MISC     0.7887    0.7920    0.7903       702
             ORG     0.8470    0.8862    0.8661      1661
             PER     0.9576    0.9505    0.9541      1617

all (micro avg.)     0.8875    0.9053    0.8963      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.86
                  precision    recall  f1-score   support

             LOC     0.9117    0.9287    0.9201      1668
            MISC     0.7738    0.8091    0.7911       702
             ORG     0.8518    0.8790    0.8652      1661
             PER     0.9580    0.9598    0.9589      1617

all (micro avg.)     0.8894    0.9081    0.8986      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9001    0.9400    0.9196      1668
            MISC     0.7705    0.7892    0.7797       702
             ORG     0.8503    0.8718    0.8609      1661
             PER     0.9543    0.9549    0.9546      1617

all (micro avg.)     0.8845    0.9055    0.8948      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 88.95
                  precision    recall  f1-score   support

             LOC     0.8953    0.9275    0.9111      1668
            MISC     0.7716    0.7749    0.7733       702
             ORG     0.8440    0.8700    0.8568      1661
             PER     0.9412    0.9610    0.9510      1617

all (micro avg.)     0.8782    0.9012    0.8895      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.51
                  precision    recall  f1-score   support

             LOC     0.9081    0.9299    0.9188      1668
            MISC     0.7872    0.8063    0.7966       702
             ORG     0.8402    0.8736    0.8566      1661
             PER     0.9571    0.9511    0.9541      1617

all (micro avg.)     0.8863    0.9040    0.8951      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 89.62
                  precision    recall  f1-score   support

             LOC     0.9037    0.9335    0.9183      1668
            MISC     0.7786    0.7963    0.7873       702
             ORG     0.8458    0.8820    0.8635      1661
             PER     0.9537    0.9561    0.9549      1617

all (micro avg.)     0.8849    0.9078    0.8962      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.90
                  precision    recall  f1-score   support

             LOC     0.9060    0.9365    0.9210      1668
            MISC     0.8029    0.7949    0.7989       702
             ORG     0.8480    0.8898    0.8684      1661
             PER     0.9540    0.9493    0.9516      1617

all (micro avg.)     0.8894    0.9088    0.8990      5648

----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.8953    0.9275    0.9111      1668
            MISC     0.7716    0.7749    0.7733       702
             ORG     0.8440    0.8700    0.8568      1661
             PER     0.9412    0.9610    0.9510      1617

all (micro avg.)     0.8782    0.9012    0.8895      5648


** Best ** model scores - run 0
                  precision    recall  f1-score   support

             LOC     0.9103    0.9311    0.9206      1668
            MISC     0.7730    0.8006    0.7866       702
             ORG     0.8603    0.8826    0.8713      1661
             PER     0.9569    0.9623    0.9596      1617

all (micro avg.)     0.8914    0.9095    0.9004      5648

----------------------------------------------------------------------

Average over 2 folds
                  precision    recall  f1-score   support

             LOC     0.9067    0.9312    0.9187      1668
            MISC     0.7801    0.7937    0.7868       702
             ORG     0.8480    0.8805    0.8639      1661
             PER     0.9536    0.9562    0.9549      1617

all (micro avg.)     0.8866    0.9063    0.8964


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 63743.944 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.9064    0.9347    0.9203      1668
            MISC     0.7782    0.7949    0.7865       702
             ORG     0.8578    0.8826    0.8700      1661
             PER     0.9578    0.9555    0.9567      1617

all (micro avg.)     0.8904    0.9079    0.8991      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.97
                  precision    recall  f1-score   support

             LOC     0.9178    0.9299    0.9238      1668
            MISC     0.7907    0.7963    0.7935       702
             ORG     0.8502    0.8886    0.8690      1661
             PER     0.9474    0.9586    0.9530      1617

all (micro avg.)     0.8903    0.9093    0.8997      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.30
                  precision    recall  f1-score   support

             LOC     0.9081    0.9359    0.9218      1668
            MISC     0.7932    0.8034    0.7983       702
             ORG     0.8689    0.8820    0.8754      1661
             PER     0.9512    0.9635    0.9573      1617

all (micro avg.)     0.8947    0.9115    0.9030      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.31
                  precision    recall  f1-score   support

             LOC     0.9127    0.9341    0.9233      1668
            MISC     0.7911    0.8091    0.8000       702
             ORG     0.8648    0.8856    0.8751      1661
             PER     0.9522    0.9604    0.9563      1617

all (micro avg.)     0.8946    0.9118    0.9031      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.45
                  precision    recall  f1-score   support

             LOC     0.9192    0.9347    0.9269      1668
            MISC     0.7997    0.7963    0.7980       702
             ORG     0.8648    0.8934    0.8789      1661
             PER     0.9470    0.9604    0.9536      1617

all (micro avg.)     0.8964    0.9127    0.9045      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.49
                  precision    recall  f1-score   support

             LOC     0.9199    0.9365    0.9281      1668
            MISC     0.7944    0.8091    0.8017       702
             ORG     0.8613    0.8934    0.8771      1661
             PER     0.9589    0.9518    0.9553      1617

all (micro avg.)     0.8976    0.9124    0.9049      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.72
                  precision    recall  f1-score   support

             LOC     0.9131    0.9388    0.9258      1668
            MISC     0.8017    0.8063    0.8040       702
             ORG     0.8686    0.8952    0.8817      1661
             PER     0.9581    0.9604    0.9592      1617

all (micro avg.)     0.8989    0.9157    0.9072      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.29
                  precision    recall  f1-score   support

             LOC     0.9076    0.9359    0.9215      1668
            MISC     0.7896    0.8020    0.7958       702
             ORG     0.8654    0.8862    0.8757      1661
             PER     0.9597    0.9573    0.9585      1617

all (micro avg.)     0.8951    0.9108    0.9029      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.19
                  precision    recall  f1-score   support

             LOC     0.9037    0.9341    0.9186      1668
            MISC     0.7877    0.8034    0.7955       702
             ORG     0.8645    0.8796    0.8720      1661
             PER     0.9611    0.9629    0.9620      1617

all (micro avg.)     0.8939    0.9101    0.9019      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.32
                  precision    recall  f1-score   support

             LOC     0.9155    0.9293    0.9223      1668
            MISC     0.8082    0.8105    0.8094       702
             ORG     0.8473    0.8989    0.8723      1661
             PER     0.9578    0.9555    0.9567      1617

all (micro avg.)     0.8935    0.9131    0.9032      5648

----------------------------------------------------------------------

** Worst ** model scores - run 0
                  precision    recall  f1-score   support

             LOC     0.9064    0.9347    0.9203      1668
            MISC     0.7782    0.7949    0.7865       702
             ORG     0.8578    0.8826    0.8700      1661
             PER     0.9578    0.9555    0.9567      1617

all (micro avg.)     0.8904    0.9079    0.8991      5648


** Best ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9131    0.9388    0.9258      1668
            MISC     0.8017    0.8063    0.8040       702
             ORG     0.8686    0.8952    0.8817      1661
             PER     0.9581    0.9604    0.9592      1617

all (micro avg.)     0.8989    0.9157    0.9072      5648

----------------------------------------------------------------------

Average over 2 folds
                  precision    recall  f1-score   support

             LOC     0.9124    0.9344    0.9232      1668
            MISC     0.7935    0.8031    0.7983       702
             ORG     0.8614    0.8886    0.8747      1661
             PER     0.9551    0.9586    0.9569      1617

all (micro avg.)     0.8945    0.9115    0.9029 



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10

training runtime: 29956.487 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.01
                  precision    recall  f1-score   support

             LOC     0.9153    0.9394    0.9272      1668
            MISC     0.8023    0.7977    0.8000       702
             ORG     0.8982    0.8820    0.8900      1661
             PER     0.9610    0.9598    0.9604      1617

all (micro avg.)     0.9095    0.9108    0.9101      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.38
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8931    0.8898    0.8914      1661
             PER     0.9606    0.9660    0.9633      1617

all (micro avg.)     0.9127    0.9148    0.9138      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9204    0.9359    0.9281      1668
            MISC     0.8107    0.7806    0.7954       702
             ORG     0.8852    0.8910    0.8881      1661
             PER     0.9657    0.9579    0.9618      1617

all (micro avg.)     0.9097    0.9097    0.9097      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9110    0.9329    0.9218      1668
            MISC     0.8290    0.7806    0.8041       702
             ORG     0.8828    0.8983    0.8905      1661
             PER     0.9628    0.9604    0.9616      1617

all (micro avg.)     0.9078    0.9117    0.9097      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.92
                  precision    recall  f1-score   support

             LOC     0.9149    0.9347    0.9247      1668
            MISC     0.8356    0.7892    0.8117       702
             ORG     0.8809    0.8904    0.8856      1661
             PER     0.9535    0.9629    0.9582      1617

all (micro avg.)     0.9067    0.9117    0.9092      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.25
                  precision    recall  f1-score   support

             LOC     0.9189    0.9371    0.9279      1668
            MISC     0.8076    0.8191    0.8133       702
             ORG     0.8934    0.8880    0.8907      1661
             PER     0.9600    0.9641    0.9620      1617

all (micro avg.)     0.9093    0.9157    0.9125      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.03
                  precision    recall  f1-score   support

             LOC     0.9162    0.9371    0.9265      1668
            MISC     0.8109    0.8063    0.8086       702
             ORG     0.8879    0.8826    0.8853      1661
             PER     0.9664    0.9604    0.9634      1617

all (micro avg.)     0.9092    0.9115    0.9103      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.07
                  precision    recall  f1-score   support

             LOC     0.9233    0.9376    0.9304      1668
            MISC     0.8126    0.8091    0.8108       702
             ORG     0.8826    0.8874    0.8850      1661
             PER     0.9604    0.9598    0.9601      1617

all (micro avg.)     0.9083    0.9132    0.9107      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.90
                  precision    recall  f1-score   support

             LOC     0.9108    0.9365    0.9234      1668
            MISC     0.8129    0.8048    0.8089       702
             ORG     0.8964    0.8808    0.8886      1661
             PER     0.9551    0.9604    0.9578      1617

all (micro avg.)     0.9074    0.9106    0.9090      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.78
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8200    0.7721    0.7953       702
             ORG     0.8729    0.8928    0.8827      1661
             PER     0.9616    0.9604    0.9610      1617

all (micro avg.)     0.9060    0.9095    0.9078      5648

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8200    0.7721    0.7953       702
             ORG     0.8729    0.8928    0.8827      1661
             PER     0.9616    0.9604    0.9610      1617

all (micro avg.)     0.9060    0.9095    0.9078      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8931    0.8898    0.8914      1661
             PER     0.9606    0.9660    0.9633      1617

all (micro avg.)     0.9127    0.9148    0.9138      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9178    0.9363    0.9269      1668
            MISC     0.8154    0.7963    0.8056       702
             ORG     0.8873    0.8883    0.8878      1661
             PER     0.9607    0.9612    0.9610      1617

all (micro avg.)     0.9087    0.9119    0.9103


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 75450.822 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.34
                  precision    recall  f1-score   support

             LOC     0.9154    0.9406    0.9279      1668
            MISC     0.8218    0.7949    0.8081       702
             ORG     0.8936    0.8946    0.8941      1661
             PER     0.9641    0.9623    0.9632      1617

all (micro avg.)     0.9116    0.9152    0.9134      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.23
                  precision    recall  f1-score   support

             LOC     0.9160    0.9418    0.9288      1668
            MISC     0.8151    0.7977    0.8063       702
             ORG     0.8977    0.8880    0.8929      1661
             PER     0.9599    0.9610    0.9604      1617

all (micro avg.)     0.9110    0.9136    0.9123      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.34
                  precision    recall  f1-score   support

             LOC     0.9154    0.9400    0.9275      1668
            MISC     0.8240    0.8134    0.8186       702
             ORG     0.8868    0.8916    0.8892      1661
             PER     0.9665    0.9623    0.9644      1617

all (micro avg.)     0.9103    0.9164    0.9134      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.45
                  precision    recall  f1-score   support

             LOC     0.9231    0.9424    0.9327      1668
            MISC     0.8008    0.8077    0.8043       702
             ORG     0.9056    0.8892    0.8973      1661
             PER     0.9571    0.9647    0.9609      1617

all (micro avg.)     0.9126    0.9164    0.9145      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 91.18
                  precision    recall  f1-score   support

             LOC     0.9175    0.9400    0.9286      1668
            MISC     0.7978    0.8148    0.8062       702
             ORG     0.9022    0.8832    0.8926      1661
             PER     0.9570    0.9629    0.9599      1617

all (micro avg.)     0.9093    0.9143    0.9118      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.69
                  precision    recall  f1-score   support

             LOC     0.9241    0.9412    0.9326      1668
            MISC     0.8282    0.8034    0.8156       702
             ORG     0.8989    0.8940    0.8965      1661
             PER     0.9642    0.9654    0.9648      1617

all (micro avg.)     0.9167    0.9171    0.9169      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.35
                  precision    recall  f1-score   support

             LOC     0.9273    0.9400    0.9336      1668
            MISC     0.8040    0.8063    0.8051       702
             ORG     0.8892    0.8940    0.8916      1661
             PER     0.9634    0.9610    0.9622      1617

all (micro avg.)     0.9111    0.9159    0.9135      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.56
                  precision    recall  f1-score   support

             LOC     0.9304    0.9371    0.9337      1668
            MISC     0.8328    0.7877    0.8097       702
             ORG     0.8891    0.9073    0.8981      1661
             PER     0.9502    0.9685    0.9593      1617

all (micro avg.)     0.9124    0.9187    0.9156      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.29
                  precision    recall  f1-score   support

             LOC     0.9220    0.9353    0.9286      1668
            MISC     0.8262    0.7920    0.8087       702
             ORG     0.8854    0.9025    0.8939      1661
             PER     0.9627    0.9586    0.9606      1617

all (micro avg.)     0.9113    0.9145    0.9129      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.27
                  precision    recall  f1-score   support

             LOC     0.9144    0.9412    0.9276      1668
            MISC     0.8048    0.8048    0.8048       702
             ORG     0.8985    0.8904    0.8945      1661
             PER     0.9646    0.9604    0.9625      1617

all (micro avg.)     0.9105    0.9148    0.9127      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9175    0.9400    0.9286      1668
            MISC     0.7978    0.8148    0.8062       702
             ORG     0.9022    0.8832    0.8926      1661
             PER     0.9570    0.9629    0.9599      1617

all (micro avg.)     0.9093    0.9143    0.9118      5648


** Best ** model scores - run 5
                  precision    recall  f1-score   support

             LOC     0.9241    0.9412    0.9326      1668
            MISC     0.8282    0.8034    0.8156       702
             ORG     0.8989    0.8940    0.8965      1661
             PER     0.9642    0.9654    0.9648      1617

all (micro avg.)     0.9167    0.9171    0.9169      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9205    0.9400    0.9302      1668
            MISC     0.8156    0.8023    0.8088       702
             ORG     0.8947    0.8935    0.8941      1661
             PER     0.9610    0.9627    0.9618      1617

all (micro avg.)     0.9117    0.9157    0.9137





> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_ChainCRF --embedding glove-840B --fold-count 10

training runtime: 27987.675 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.79
                  precision    recall  f1-score   support

             LOC     0.8997    0.9406    0.9197      1668
            MISC     0.8088    0.8077    0.8083       702
             ORG     0.8998    0.8706    0.8849      1661
             PER     0.9675    0.9567    0.9621      1617

all (micro avg.)     0.9076    0.9081    0.9079      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 90.88
                  precision    recall  f1-score   support

             LOC     0.9134    0.9359    0.9245      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8919    0.8742    0.8829      1661
             PER     0.9571    0.9666    0.9618      1617

all (micro avg.)     0.9075    0.9101    0.9088      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.81
                  precision    recall  f1-score   support

             LOC     0.9189    0.9311    0.9250      1668
            MISC     0.8088    0.7835    0.7959       702
             ORG     0.8816    0.8922    0.8869      1661
             PER     0.9645    0.9567    0.9606      1617

all (micro avg.)     0.9075    0.9086    0.9081      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.06
                  precision    recall  f1-score   support

             LOC     0.9174    0.9388    0.9280      1668
            MISC     0.8252    0.8205    0.8229       702
             ORG     0.8809    0.8814    0.8811      1661
             PER     0.9616    0.9598    0.9607      1617

all (micro avg.)     0.9079    0.9132    0.9106      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 91.31
                  precision    recall  f1-score   support

             LOC     0.9287    0.9299    0.9293      1668
            MISC     0.8326    0.8077    0.8200       702
             ORG     0.8749    0.8970    0.8859      1661
             PER     0.9642    0.9647    0.9645      1617

all (micro avg.)     0.9111    0.9150    0.9131      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.87
                  precision    recall  f1-score   support

             LOC     0.9212    0.9317    0.9264      1668
            MISC     0.7958    0.8162    0.8059       702
             ORG     0.8845    0.8850    0.8847      1661
             PER     0.9616    0.9592    0.9604      1617

all (micro avg.)     0.9060    0.9115    0.9087      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.82
                  precision    recall  f1-score   support

             LOC     0.9001    0.9448    0.9219      1668
            MISC     0.8139    0.8034    0.8086       702
             ORG     0.9030    0.8742    0.8883      1661
             PER     0.9556    0.9579    0.9568      1617

all (micro avg.)     0.9062    0.9102    0.9082      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9278    0.9329    0.9303      1668
            MISC     0.8048    0.8048    0.8048       702
             ORG     0.8852    0.8868    0.8860      1661
             PER     0.9468    0.9685    0.9575      1617

all (micro avg.)     0.9057    0.9136    0.9097      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.63
                  precision    recall  f1-score   support

             LOC     0.9303    0.9281    0.9292      1668
            MISC     0.8152    0.7920    0.8035       702
             ORG     0.8668    0.8934    0.8799      1661
             PER     0.9509    0.9573    0.9541      1617

all (micro avg.)     0.9033    0.9093    0.9063      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.55
                  precision    recall  f1-score   support

             LOC     0.9089    0.9329    0.9207      1668
            MISC     0.8162    0.7906    0.8032       702
             ORG     0.8731    0.8904    0.8817      1661
             PER     0.9649    0.9518    0.9583      1617

all (micro avg.)     0.9028    0.9081    0.9055      5648

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

             LOC     0.9089    0.9329    0.9207      1668
            MISC     0.8162    0.7906    0.8032       702
             ORG     0.8731    0.8904    0.8817      1661
             PER     0.9649    0.9518    0.9583      1617

all (micro avg.)     0.9028    0.9081    0.9055      5648


** Best ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9287    0.9299    0.9293      1668
            MISC     0.8326    0.8077    0.8200       702
             ORG     0.8749    0.8970    0.8859      1661
             PER     0.9642    0.9647    0.9645      1617

all (micro avg.)     0.9111    0.9150    0.9131      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9166    0.9347    0.9255      1668
            MISC     0.8134    0.8030    0.8081       702
             ORG     0.8842    0.8845    0.8842      1661
             PER     0.9595    0.9599    0.9597      1617

all (micro avg.)     0.9066    0.9108    0.9087



python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_ChainCRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 52437.124 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.23
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8186    0.8162    0.8174       702
             ORG     0.8948    0.8856    0.8902      1661
             PER     0.9537    0.9672    0.9604      1617

all (micro avg.)     0.9098    0.9148    0.9123      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.28
                  precision    recall  f1-score   support

             LOC     0.9284    0.9329    0.9306      1668
            MISC     0.8095    0.7991    0.8043       702
             ORG     0.8773    0.9043    0.8906      1661
             PER     0.9700    0.9592    0.9646      1617

all (micro avg.)     0.9102    0.9154    0.9128      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.30
                  precision    recall  f1-score   support

             LOC     0.9244    0.9388    0.9316      1668
            MISC     0.8266    0.8148    0.8207       702
             ORG     0.8941    0.8898    0.8920      1661
             PER     0.9498    0.9598    0.9548      1617

all (micro avg.)     0.9110    0.9150    0.9130      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.26
                  precision    recall  f1-score   support

             LOC     0.9225    0.9347    0.9285      1668
            MISC     0.8195    0.8148    0.8171       702
             ORG     0.8818    0.9031    0.8923      1661
             PER     0.9614    0.9555    0.9584      1617

all (micro avg.)     0.9087    0.9164    0.9126      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 91.19
                  precision    recall  f1-score   support

             LOC     0.9291    0.9353    0.9322      1668
            MISC     0.8035    0.7863    0.7948       702
             ORG     0.8914    0.8940    0.8927      1661
             PER     0.9571    0.9647    0.9609      1617

all (micro avg.)     0.9108    0.9131    0.9119      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.30
                  precision    recall  f1-score   support

             LOC     0.9293    0.9293    0.9293      1668
            MISC     0.8174    0.8034    0.8103       702
             ORG     0.8797    0.9073    0.8933      1661
             PER     0.9605    0.9617    0.9611      1617

all (micro avg.)     0.9097    0.9164    0.9130      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.39
                  precision    recall  f1-score   support

             LOC     0.9229    0.9394    0.9311      1668
            MISC     0.8214    0.8191    0.8203       702
             ORG     0.8939    0.8874    0.8906      1661
             PER     0.9576    0.9629    0.9602      1617

all (micro avg.)     0.9119    0.9159    0.9139      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.98
                  precision    recall  f1-score   support

             LOC     0.9232    0.9371    0.9301      1668
            MISC     0.8046    0.7977    0.8011       702
             ORG     0.8842    0.8922    0.8882      1661
             PER     0.9597    0.9567    0.9582      1617

all (micro avg.)     0.9075    0.9122    0.9098      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.49
                  precision    recall  f1-score   support

             LOC     0.9227    0.9376    0.9301      1668
            MISC     0.8119    0.8177    0.8148       702
             ORG     0.8953    0.8904    0.8928      1661
             PER     0.9689    0.9623    0.9656      1617

all (micro avg.)     0.9140    0.9159    0.9149      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.24
                  precision    recall  f1-score   support

             LOC     0.9157    0.9376    0.9265      1668
            MISC     0.8228    0.8134    0.8181       702
             ORG     0.8886    0.8928    0.8907      1661
             PER     0.9680    0.9542    0.9611      1617

all (micro avg.)     0.9110    0.9138    0.9124      5648

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9232    0.9371    0.9301      1668
            MISC     0.8046    0.7977    0.8011       702
             ORG     0.8842    0.8922    0.8882      1661
             PER     0.9597    0.9567    0.9582      1617

all (micro avg.)     0.9075    0.9122    0.9098      5648


** Best ** model scores - run 8
                  precision    recall  f1-score   support

             LOC     0.9227    0.9376    0.9301      1668
            MISC     0.8119    0.8177    0.8148       702
             ORG     0.8953    0.8904    0.8928      1661
             PER     0.9689    0.9623    0.9656      1617

all (micro avg.)     0.9140    0.9159    0.9149      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9238    0.9357    0.9297      1668
            MISC     0.8156    0.8083    0.8119       702
             ORG     0.8881    0.8947    0.8913      1661
             PER     0.9607    0.9604    0.9605      1617

all (micro avg.)     0.9105    0.9149    0.9127   



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidGRU_CRF --embedding glove-840B --fold-count 10

training runtime: 42159.586 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.37
                  precision    recall  f1-score   support

             LOC     0.9370    0.9269    0.9319      1668
            MISC     0.7903    0.7621    0.7759       702
             ORG     0.8590    0.8983    0.8782      1661
             PER     0.9471    0.9641    0.9556      1617

all (micro avg.)     0.8988    0.9086    0.9037      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 90.55
                  precision    recall  f1-score   support

             LOC     0.9275    0.9353    0.9313      1668
            MISC     0.7724    0.7977    0.7849       702
             ORG     0.8850    0.8850    0.8850      1661
             PER     0.9409    0.9641    0.9524      1617

all (micro avg.)     0.8994    0.9117    0.9055      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.9127    0.9341    0.9233      1668
            MISC     0.7988    0.7635    0.7808       702
             ORG     0.8616    0.8772    0.8693      1661
             PER     0.9476    0.9617    0.9546      1617

all (micro avg.)     0.8942    0.9040    0.8991      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.32
                  precision    recall  f1-score   support

             LOC     0.9211    0.9305    0.9257      1668
            MISC     0.7806    0.7806    0.7806       702
             ORG     0.8782    0.8772    0.8777      1661
             PER     0.9547    0.9635    0.9591      1617

all (micro avg.)     0.9008    0.9056    0.9032      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.8926    0.9365    0.9140      1668
            MISC     0.8063    0.7707    0.7881       702
             ORG     0.8991    0.8633    0.8808      1661
             PER     0.9367    0.9604    0.9484      1617

all (micro avg.)     0.8971    0.9012    0.8991      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.22
                  precision    recall  f1-score   support

             LOC     0.9282    0.9305    0.9293      1668
            MISC     0.7531    0.7821    0.7673       702
             ORG     0.8888    0.8802    0.8845      1661
             PER     0.9333    0.9697    0.9512      1617

all (micro avg.)     0.8961    0.9085    0.9022      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.49
                  precision    recall  f1-score   support

             LOC     0.9135    0.9365    0.9248      1668
            MISC     0.7816    0.7849    0.7832       702
             ORG     0.8955    0.8772    0.8863      1661
             PER     0.9477    0.9635    0.9555      1617

all (micro avg.)     0.9019    0.9079    0.9049      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.90
                  precision    recall  f1-score   support

             LOC     0.9070    0.9353    0.9209      1668
            MISC     0.7523    0.8048    0.7777       702
             ORG     0.8846    0.8766    0.8806      1661
             PER     0.9357    0.9623    0.9488      1617

all (micro avg.)     0.8888    0.9095    0.8990      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.09
                  precision    recall  f1-score   support

             LOC     0.9105    0.9329    0.9215      1668
            MISC     0.7874    0.7650    0.7760       702
             ORG     0.8844    0.8844    0.8844      1661
             PER     0.9341    0.9641    0.9489      1617

all (micro avg.)     0.8951    0.9067    0.9009      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.96
                  precision    recall  f1-score   support

             LOC     0.9045    0.9365    0.9202      1668
            MISC     0.8259    0.7635    0.7935       702
             ORG     0.8725    0.8772    0.8748      1661
             PER     0.9360    0.9586    0.9471      1617

all (micro avg.)     0.8953    0.9039    0.8996      5648

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9070    0.9353    0.9209      1668
            MISC     0.7523    0.8048    0.7777       702
             ORG     0.8846    0.8766    0.8806      1661
             PER     0.9357    0.9623    0.9488      1617

all (micro avg.)     0.8888    0.9095    0.8990      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9275    0.9353    0.9313      1668
            MISC     0.7724    0.7977    0.7849       702
             ORG     0.8850    0.8850    0.8850      1661
             PER     0.9409    0.9641    0.9524      1617

all (micro avg.)     0.8994    0.9117    0.9055      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9154    0.9335    0.9243      1668
            MISC     0.7849    0.7775    0.7808       702
             ORG     0.8809    0.8797    0.8802      1661
             PER     0.9414    0.9632    0.9521      1617

all (micro avg.)     0.8967    0.9068    0.9017 


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidGRU_CRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 112655.109 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.13
                  precision    recall  f1-score   support

             LOC     0.9258    0.9353    0.9305      1668
            MISC     0.8157    0.8006    0.8081       702
             ORG     0.8883    0.8904    0.8894      1661
             PER     0.9425    0.9734    0.9577      1617

all (micro avg.)     0.9065    0.9163    0.9113      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.40
                  precision    recall  f1-score   support

             LOC     0.9246    0.9406    0.9325      1668
            MISC     0.8157    0.8006    0.8081       702
             ORG     0.8909    0.8898    0.8904      1661
             PER     0.9579    0.9709    0.9644      1617

all (micro avg.)     0.9112    0.9170    0.9140      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.90
                  precision    recall  f1-score   support

             LOC     0.9305    0.9311    0.9308      1668
            MISC     0.8091    0.8091    0.8091       702
             ORG     0.8669    0.8983    0.8823      1661
             PER     0.9562    0.9592    0.9577      1617

all (micro avg.)     0.9037    0.9143    0.9090      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.21
                  precision    recall  f1-score   support

             LOC     0.9242    0.9359    0.9300      1668
            MISC     0.7943    0.7977    0.7960       702
             ORG     0.8935    0.8989    0.8962      1661
             PER     0.9531    0.9672    0.9601      1617

all (micro avg.)     0.9075    0.9168    0.9121      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.66
                  precision    recall  f1-score   support

             LOC     0.9178    0.9311    0.9244      1668
            MISC     0.8092    0.7792    0.7939       702
             ORG     0.8809    0.8862    0.8836      1661
             PER     0.9508    0.9678    0.9592      1617

all (micro avg.)     0.9036    0.9095    0.9066      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.04
                  precision    recall  f1-score   support

             LOC     0.9282    0.9305    0.9293      1668
            MISC     0.8128    0.7977    0.8052       702
             ORG     0.8834    0.8898    0.8866      1661
             PER     0.9537    0.9672    0.9604      1617

all (micro avg.)     0.9084    0.9125    0.9104      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.61
                  precision    recall  f1-score   support

             LOC     0.9219    0.9347    0.9283      1668
            MISC     0.7886    0.7863    0.7874       702
             ORG     0.8757    0.8862    0.8809      1661
             PER     0.9553    0.9654    0.9603      1617

all (micro avg.)     0.9015    0.9108    0.9061      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.21
                  precision    recall  f1-score   support

             LOC     0.9265    0.9365    0.9314      1668
            MISC     0.8057    0.8091    0.8074       702
             ORG     0.8906    0.8922    0.8914      1661
             PER     0.9513    0.9660    0.9586      1617

all (micro avg.)     0.9082    0.9161    0.9121      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.13
                  precision    recall  f1-score   support

             LOC     0.9235    0.9335    0.9284      1668
            MISC     0.8169    0.8006    0.8086       702
             ORG     0.8821    0.8964    0.8892      1661
             PER     0.9604    0.9604    0.9604      1617

all (micro avg.)     0.9088    0.9138    0.9113      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.11
                  precision    recall  f1-score   support

             LOC     0.9311    0.9323    0.9317      1668
            MISC     0.8052    0.7949    0.8000       702
             ORG     0.8720    0.9067    0.8890      1661
             PER     0.9622    0.9598    0.9610      1617

all (micro avg.)     0.9067    0.9155    0.9111      5648

----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9219    0.9347    0.9283      1668
            MISC     0.7886    0.7863    0.7874       702
             ORG     0.8757    0.8862    0.8809      1661
             PER     0.9553    0.9654    0.9603      1617

all (micro avg.)     0.9015    0.9108    0.9061      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9246    0.9406    0.9325      1668
            MISC     0.8157    0.8006    0.8081       702
             ORG     0.8909    0.8898    0.8904      1661
             PER     0.9579    0.9709    0.9644      1617

all (micro avg.)     0.9112    0.9170    0.9140      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9254    0.9341    0.9297      1668
            MISC     0.8073    0.7976    0.8024       702
             ORG     0.8824    0.8935    0.8879      1661
             PER     0.9543    0.9657    0.9600      1617

all (micro avg.)     0.9066    0.9143    0.9104 


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN --embedding glove-840B --fold-count 10

training runtime: 28500.657 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 89.64
                  precision    recall  f1-score   support

             LOC     0.9118    0.9239    0.9178      1668
            MISC     0.7991    0.7877    0.7934       702
             ORG     0.8385    0.8910    0.8640      1661
             PER     0.9502    0.9555    0.9528      1617

all (micro avg.)     0.8867    0.9063    0.8964      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.96
                  precision    recall  f1-score   support

             LOC     0.9135    0.9311    0.9222      1668
            MISC     0.8028    0.8120    0.8074       702
             ORG     0.8401    0.8856    0.8623      1661
             PER     0.9538    0.9573    0.9556      1617

all (micro avg.)     0.8890    0.9104    0.8996      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9091    0.9293    0.9191      1668
            MISC     0.7884    0.7963    0.7923       702
             ORG     0.8281    0.8814    0.8539      1661
             PER     0.9574    0.9579    0.9577      1617

all (micro avg.)     0.8831    0.9069    0.8948      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 89.56
                  precision    recall  f1-score   support

             LOC     0.9059    0.9347    0.9200      1668
            MISC     0.8000    0.7863    0.7931       702
             ORG     0.8472    0.8712    0.8590      1661
             PER     0.9473    0.9567    0.9520      1617

all (micro avg.)     0.8875    0.9039    0.8956      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.12
                  precision    recall  f1-score   support

             LOC     0.8959    0.9341    0.9146      1668
            MISC     0.7732    0.7963    0.7846       702
             ORG     0.8462    0.8675    0.8567      1661
             PER     0.9421    0.9561    0.9490      1617

all (micro avg.)     0.8791    0.9037    0.8912      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 89.19
                  precision    recall  f1-score   support

             LOC     0.9060    0.9299    0.9178      1668
            MISC     0.7717    0.7849    0.7782       702
             ORG     0.8342    0.8814    0.8571      1661
             PER     0.9534    0.9493    0.9513      1617

all (micro avg.)     0.8808    0.9032    0.8919      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 89.19
                  precision    recall  f1-score   support

             LOC     0.9017    0.9347    0.9179      1668
            MISC     0.7880    0.8048    0.7963       702
             ORG     0.8373    0.8675    0.8522      1661
             PER     0.9430    0.9524    0.9477      1617

all (micro avg.)     0.8802    0.9039    0.8919      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9124    0.9305    0.9213      1668
            MISC     0.8011    0.7977    0.7994       702
             ORG     0.8281    0.8874    0.8567      1661
             PER     0.9432    0.9542    0.9487      1617

all (micro avg.)     0.8819    0.9081    0.8948      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 89.61
                  precision    recall  f1-score   support

             LOC     0.9001    0.9347    0.9171      1668
            MISC     0.7954    0.7920    0.7937       702
             ORG     0.8474    0.8796    0.8632      1661
             PER     0.9485    0.9567    0.9526      1617

all (micro avg.)     0.8854    0.9070    0.8961      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.68
                  precision    recall  f1-score   support

             LOC     0.9071    0.9311    0.9189      1668
            MISC     0.7872    0.8063    0.7966       702
             ORG     0.8453    0.8814    0.8630      1661
             PER     0.9452    0.9604    0.9528      1617

all (micro avg.)     0.8846    0.9093    0.8968      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.8959    0.9341    0.9146      1668
            MISC     0.7732    0.7963    0.7846       702
             ORG     0.8462    0.8675    0.8567      1661
             PER     0.9421    0.9561    0.9490      1617

all (micro avg.)     0.8791    0.9037    0.8912      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9135    0.9311    0.9222      1668
            MISC     0.8028    0.8120    0.8074       702
             ORG     0.8401    0.8856    0.8623      1661
             PER     0.9538    0.9573    0.9556      1617

all (micro avg.)     0.8890    0.9104    0.8996      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9064    0.9314    0.9187      1668
            MISC     0.7907    0.7964    0.7935       702
             ORG     0.8392    0.8794    0.8588      1661
             PER     0.9484    0.9557    0.9520      1617

all (micro avg.)     0.8838    0.9063    0.8949




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 41234.934 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 89.90
                  precision    recall  f1-score   support

             LOC     0.9048    0.9347    0.9195      1668
            MISC     0.7922    0.8091    0.8006       702
             ORG     0.8590    0.8766    0.8677      1661
             PER     0.9463    0.9592    0.9527      1617

all (micro avg.)     0.8892    0.9090    0.8990      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.79
                  precision    recall  f1-score   support

             LOC     0.9157    0.9311    0.9233      1668
            MISC     0.7949    0.7949    0.7949       702
             ORG     0.8426    0.8862    0.8638      1661
             PER     0.9479    0.9561    0.9520      1617

all (micro avg.)     0.8880    0.9081    0.8979      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.69
                  precision    recall  f1-score   support

             LOC     0.9029    0.9311    0.9168      1668
            MISC     0.8026    0.7934    0.7980       702
             ORG     0.8481    0.8838    0.8656      1661
             PER     0.9456    0.9573    0.9514      1617

all (micro avg.)     0.8865    0.9076    0.8969      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.07
                  precision    recall  f1-score   support

             LOC     0.9076    0.9359    0.9215      1668
            MISC     0.8035    0.7920    0.7977       702
             ORG     0.8560    0.8874    0.8714      1661
             PER     0.9480    0.9592    0.9536      1617

all (micro avg.)     0.8912    0.9104    0.9007      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.73
                  precision    recall  f1-score   support

             LOC     0.9008    0.9365    0.9183      1668
            MISC     0.7919    0.8077    0.7997       702
             ORG     0.8558    0.8790    0.8672      1661
             PER     0.9427    0.9561    0.9493      1617

all (micro avg.)     0.8860    0.9092    0.8974      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 89.94
                  precision    recall  f1-score   support

             LOC     0.9028    0.9406    0.9213      1668
            MISC     0.7938    0.8006    0.7972       702
             ORG     0.8627    0.8742    0.8684      1661
             PER     0.9491    0.9567    0.9529      1617

all (micro avg.)     0.8908    0.9083    0.8994      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.13
                  precision    recall  f1-score   support

             LOC     0.9140    0.9305    0.9222      1668
            MISC     0.7986    0.7963    0.7974       702
             ORG     0.8564    0.8940    0.8748      1661
             PER     0.9479    0.9567    0.9523      1617

all (micro avg.)     0.8923    0.9106    0.9013      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.83
                  precision    recall  f1-score   support

             LOC     0.9075    0.9293    0.9182      1668
            MISC     0.7887    0.7977    0.7932       702
             ORG     0.8540    0.8838    0.8686      1661
             PER     0.9448    0.9629    0.9538      1617

all (micro avg.)     0.8876    0.9092    0.8983      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 89.71
                  precision    recall  f1-score   support

             LOC     0.9115    0.9329    0.9221      1668
            MISC     0.7980    0.7877    0.7928       702
             ORG     0.8474    0.8856    0.8661      1661
             PER     0.9409    0.9555    0.9481      1617

all (micro avg.)     0.8870    0.9074    0.8971      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.76
                  precision    recall  f1-score   support

             LOC     0.9060    0.9359    0.9207      1668
            MISC     0.7957    0.7991    0.7974       702
             ORG     0.8488    0.8790    0.8636      1661
             PER     0.9490    0.9555    0.9522      1617

all (micro avg.)     0.8876    0.9078    0.8976      5648

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9029    0.9311    0.9168      1668
            MISC     0.8026    0.7934    0.7980       702
             ORG     0.8481    0.8838    0.8656      1661
             PER     0.9456    0.9573    0.9514      1617

all (micro avg.)     0.8865    0.9076    0.8969      5648


** Best ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9140    0.9305    0.9222      1668
            MISC     0.7986    0.7963    0.7974       702
             ORG     0.8564    0.8940    0.8748      1661
             PER     0.9479    0.9567    0.9523      1617

all (micro avg.)     0.8923    0.9106    0.9013      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9074    0.9338    0.9204      1668
            MISC     0.7960    0.7979    0.7969       702
             ORG     0.8531    0.8830    0.8677      1661
             PER     0.9462    0.9575    0.9518      1617

all (micro avg.)     0.8886    0.9087    0.8985  



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN_CRF --embedding glove-840B --fold-count 10

training runtime: 25486.061 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.39
                  precision    recall  f1-score   support

             LOC     0.9256    0.9323    0.9289      1668
            MISC     0.8047    0.7749    0.7896       702
             ORG     0.8545    0.9019    0.8776      1661
             PER     0.9588    0.9505    0.9547      1617

all (micro avg.)     0.8988    0.9090    0.9039      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 90.46
                  precision    recall  f1-score   support

             LOC     0.9161    0.9365    0.9262      1668
            MISC     0.8056    0.7792    0.7922       702
             ORG     0.8643    0.8977    0.8807      1661
             PER     0.9521    0.9579    0.9550      1617

all (micro avg.)     0.8977    0.9117    0.9046      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.20
                  precision    recall  f1-score   support

             LOC     0.9123    0.9359    0.9239      1668
            MISC     0.8074    0.7764    0.7916       702
             ORG     0.8608    0.8862    0.8733      1661
             PER     0.9510    0.9604    0.9557      1617

all (micro avg.)     0.8956    0.9085    0.9020      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.81
                  precision    recall  f1-score   support

             LOC     0.9335    0.9257    0.9296      1668
            MISC     0.8169    0.8006    0.8086       702
             ORG     0.8730    0.8983    0.8855      1661
             PER     0.9468    0.9573    0.9520      1617

all (micro avg.)     0.9050    0.9111    0.9081      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.69
                  precision    recall  f1-score   support

             LOC     0.9122    0.9341    0.9230      1668
            MISC     0.8070    0.7920    0.7994       702
             ORG     0.8729    0.8970    0.8848      1661
             PER     0.9621    0.9567    0.9594      1617

all (micro avg.)     0.9018    0.9120    0.9069      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.77
                  precision    recall  f1-score   support

             LOC     0.9096    0.9412    0.9252      1668
            MISC     0.8190    0.7863    0.8023       702
             ORG     0.8818    0.8940    0.8879      1661
             PER     0.9503    0.9586    0.9544      1617

all (micro avg.)     0.9024    0.9131    0.9077      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.23
                  precision    recall  f1-score   support

             LOC     0.9250    0.9388    0.9319      1668
            MISC     0.8245    0.7963    0.8101       702
             ORG     0.8862    0.8958    0.8910      1661
             PER     0.9540    0.9610    0.9575      1617

all (micro avg.)     0.9098    0.9148    0.9123      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.61
                  precision    recall  f1-score   support

             LOC     0.9181    0.9347    0.9263      1668
            MISC     0.8112    0.7835    0.7971       702
             ORG     0.8638    0.8977    0.8804      1661
             PER     0.9586    0.9586    0.9586      1617

all (micro avg.)     0.9005    0.9118    0.9061      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.24
                  precision    recall  f1-score   support

             LOC     0.9182    0.9287    0.9234      1668
            MISC     0.8183    0.7892    0.8035       702
             ORG     0.8540    0.8946    0.8739      1661
             PER     0.9616    0.9450    0.9532      1617

all (micro avg.)     0.8988    0.9060    0.9024      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.05
                  precision    recall  f1-score   support

             LOC     0.9192    0.9412    0.9301      1668
            MISC     0.8243    0.8020    0.8130       702
             ORG     0.8759    0.8964    0.8860      1661
             PER     0.9517    0.9623    0.9569      1617

all (micro avg.)     0.9043    0.9168    0.9105      5648

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9123    0.9359    0.9239      1668
            MISC     0.8074    0.7764    0.7916       702
             ORG     0.8608    0.8862    0.8733      1661
             PER     0.9510    0.9604    0.9557      1617

all (micro avg.)     0.8956    0.9085    0.9020      5648


** Best ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9250    0.9388    0.9319      1668
            MISC     0.8245    0.7963    0.8101       702
             ORG     0.8862    0.8958    0.8910      1661
             PER     0.9540    0.9610    0.9575      1617

all (micro avg.)     0.9098    0.9148    0.9123      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9190    0.9349    0.9268      1668
            MISC     0.8139    0.7880    0.8007       702
             ORG     0.8687    0.8960    0.8821      1661
             PER     0.9547    0.9568    0.9557      1617

all (micro avg.)     0.9015    0.9115    0.9064 


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN_CRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 31835.516 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.99
                  precision    recall  f1-score   support

             LOC     0.8990    0.9442    0.9211      1668
            MISC     0.8084    0.7991    0.8037       702
             ORG     0.9034    0.8838    0.8935      1661
             PER     0.9537    0.9672    0.9604      1617

all (micro avg.)     0.9049    0.9150    0.9099      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.04
                  precision    recall  f1-score   support

             LOC     0.9243    0.9376    0.9310      1668
            MISC     0.8275    0.8134    0.8204       702
             ORG     0.8768    0.8910    0.8838      1661
             PER     0.9454    0.9641    0.9547      1617

all (micro avg.)     0.9047    0.9161    0.9104      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.17
                  precision    recall  f1-score   support

             LOC     0.9254    0.9371    0.9312      1668
            MISC     0.8158    0.7949    0.8052       702
             ORG     0.8892    0.8989    0.8940      1661
             PER     0.9526    0.9579    0.9553      1617

all (micro avg.)     0.9093    0.9141    0.9117      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.38
                  precision    recall  f1-score   support

             LOC     0.9424    0.9317    0.9370      1668
            MISC     0.8097    0.8120    0.8108       702
             ORG     0.8859    0.9019    0.8938      1661
             PER     0.9433    0.9672    0.9551      1617

all (micro avg.)     0.9095    0.9182    0.9138      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.80
                  precision    recall  f1-score   support

             LOC     0.9016    0.9448    0.9227      1668
            MISC     0.8253    0.8006    0.8127       702
             ORG     0.8892    0.8886    0.8889      1661
             PER     0.9502    0.9555    0.9528      1617

all (micro avg.)     0.9027    0.9134    0.9080      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.79
                  precision    recall  f1-score   support

             LOC     0.9424    0.9317    0.9370      1668
            MISC     0.8171    0.8020    0.8095       702
             ORG     0.8487    0.9085    0.8776      1661
             PER     0.9593    0.9468    0.9530      1617

all (micro avg.)     0.9028    0.9131    0.9079      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.62
                  precision    recall  f1-score   support

             LOC     0.9178    0.9376    0.9276      1668
            MISC     0.8343    0.7963    0.8149       702
             ORG     0.8594    0.8977    0.8781      1661
             PER     0.9490    0.9549    0.9519      1617

all (micro avg.)     0.8992    0.9132    0.9062      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.91
                  precision    recall  f1-score   support

             LOC     0.9267    0.9323    0.9295      1668
            MISC     0.8268    0.8091    0.8179       702
             ORG     0.8650    0.9025    0.8833      1661
             PER     0.9542    0.9542    0.9542      1617

all (micro avg.)     0.9038    0.9145    0.9091      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.28
                  precision    recall  f1-score   support

             LOC     0.9292    0.9365    0.9328      1668
            MISC     0.8210    0.8034    0.8121       702
             ORG     0.8829    0.8989    0.8908      1661
             PER     0.9614    0.9549    0.9581      1617

all (micro avg.)     0.9114    0.9141    0.9128      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.86
                  precision    recall  f1-score   support

             LOC     0.9168    0.9376    0.9271      1668
            MISC     0.8088    0.8077    0.8083       702
             ORG     0.8811    0.8874    0.8842      1661
             PER     0.9512    0.9641    0.9576      1617

all (micro avg.)     0.9030    0.9143    0.9086      5648

----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9178    0.9376    0.9276      1668
            MISC     0.8343    0.7963    0.8149       702
             ORG     0.8594    0.8977    0.8781      1661
             PER     0.9490    0.9549    0.9519      1617

all (micro avg.)     0.8992    0.9132    0.9062      5648


** Best ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9424    0.9317    0.9370      1668
            MISC     0.8097    0.8120    0.8108       702
             ORG     0.8859    0.9019    0.8938      1661
             PER     0.9433    0.9672    0.9551      1617

all (micro avg.)     0.9095    0.9182    0.9138      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9226    0.9371    0.9297      1668
            MISC     0.8195    0.8038    0.8115       702
             ORG     0.8781    0.8959    0.8868      1661
             PER     0.9520    0.9587    0.9553      1617

all (micro avg.)     0.9051    0.9146    0.9098



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF_CASING --embedding glove-840B --fold-count 10

training runtime: 30474.856 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.77
                  precision    recall  f1-score   support

             LOC     0.9181    0.9341    0.9260      1668
            MISC     0.7864    0.8077    0.7969       702
             ORG     0.8905    0.8766    0.8835      1661
             PER     0.9600    0.9641    0.9620      1617

all (micro avg.)     0.9054    0.9101    0.9077      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.11
                  precision    recall  f1-score   support

             LOC     0.9221    0.9365    0.9292      1668
            MISC     0.8066    0.8020    0.8043       702
             ORG     0.8993    0.8820    0.8906      1661
             PER     0.9524    0.9660    0.9592      1617

all (micro avg.)     0.9101    0.9122    0.9111      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.22
                  precision    recall  f1-score   support

             LOC     0.9137    0.9394    0.9264      1668
            MISC     0.8215    0.8063    0.8138       702
             ORG     0.9039    0.8832    0.8934      1661
             PER     0.9552    0.9623    0.9587      1617

all (micro avg.)     0.9116    0.9129    0.9122      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.31
                  precision    recall  f1-score   support

             LOC     0.9300    0.9323    0.9311      1668
            MISC     0.8097    0.8063    0.8080       702
             ORG     0.8854    0.8977    0.8915      1661
             PER     0.9640    0.9610    0.9625      1617

all (micro avg.)     0.9116    0.9147    0.9131      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.41
                  precision    recall  f1-score   support

             LOC     0.9294    0.9233    0.9263      1668
            MISC     0.7988    0.7863    0.7925       702
             ORG     0.8575    0.9061    0.8811      1661
             PER     0.9646    0.9437    0.9540      1617

all (micro avg.)     0.9011    0.9070    0.9041      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.01
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8099    0.7892    0.7994       702
             ORG     0.8780    0.8928    0.8854      1661
             PER     0.9599    0.9610    0.9604      1617

all (micro avg.)     0.9077    0.9125    0.9101      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.78
                  precision    recall  f1-score   support

             LOC     0.9269    0.9275    0.9272      1668
            MISC     0.8239    0.7863    0.8047       702
             ORG     0.8726    0.8910    0.8817      1661
             PER     0.9580    0.9592    0.9586      1617

all (micro avg.)     0.9073    0.9083    0.9078      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.09
                  precision    recall  f1-score   support

             LOC     0.9229    0.9394    0.9311      1668
            MISC     0.7933    0.8091    0.8011       702
             ORG     0.8958    0.8802    0.8879      1661
             PER     0.9616    0.9610    0.9613      1617

all (micro avg.)     0.9097    0.9120    0.9109      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.10
                  precision    recall  f1-score   support

             LOC     0.9200    0.9311    0.9255      1668
            MISC     0.8274    0.7991    0.8130       702
             ORG     0.8829    0.8940    0.8884      1661
             PER     0.9645    0.9579    0.9612      1617

all (micro avg.)     0.9105    0.9115    0.9110      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.40
                  precision    recall  f1-score   support

             LOC     0.9228    0.9382    0.9304      1668
            MISC     0.8260    0.7977    0.8116       702
             ORG     0.8948    0.8910    0.8929      1661
             PER     0.9594    0.9647    0.9621      1617

all (micro avg.)     0.9135    0.9145    0.9140      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9294    0.9233    0.9263      1668
            MISC     0.7988    0.7863    0.7925       702
             ORG     0.8575    0.9061    0.8811      1661
             PER     0.9646    0.9437    0.9540      1617

all (micro avg.)     0.9011    0.9070    0.9041      5648


** Best ** model scores - run 9
                  precision    recall  f1-score   support

             LOC     0.9228    0.9382    0.9304      1668
            MISC     0.8260    0.7977    0.8116       702
             ORG     0.8948    0.8910    0.8929      1661
             PER     0.9594    0.9647    0.9621      1617

all (micro avg.)     0.9135    0.9145    0.9140      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9233    0.9339    0.9285      1668
            MISC     0.8104    0.7990    0.8045       702
             ORG     0.8861    0.8895    0.8877      1661
             PER     0.9600    0.9601    0.9600      1617

all (micro avg.)     0.9089    0.9116    0.9102    



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_ChainCRF --embedding glove-840B --use-ELMo --fold-count 10

training runtime: 15300.362 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 92.31
                  precision    recall  f1-score   support

             LOC     0.9393    0.9365    0.9379      1668
            MISC     0.8161    0.8219    0.8190       702
             ORG     0.8934    0.9187    0.9059      1661
             PER     0.9757    0.9672    0.9714      1617

all (micro avg.)     0.9204    0.9258    0.9231      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 92.48
                  precision    recall  f1-score   support

             LOC     0.9304    0.9454    0.9379      1668
            MISC     0.8389    0.8162    0.8274       702
             ORG     0.9111    0.9013    0.9062      1661
             PER     0.9710    0.9728    0.9719      1617

all (micro avg.)     0.9254    0.9242    0.9248      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 92.42
                  precision    recall  f1-score   support

             LOC     0.9409    0.9347    0.9377      1668
            MISC     0.8209    0.8490    0.8347       702
             ORG     0.8921    0.9109    0.9014      1661
             PER     0.9717    0.9753    0.9735      1617

all (micro avg.)     0.9199    0.9286    0.9242      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 92.58
                  precision    recall  f1-score   support

             LOC     0.9381    0.9365    0.9373      1668
            MISC     0.8268    0.8362    0.8314       702
             ORG     0.9077    0.9175    0.9126      1661
             PER     0.9627    0.9746    0.9687      1617

all (micro avg.)     0.9223    0.9294    0.9258      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 92.80
                  precision    recall  f1-score   support

             LOC     0.9401    0.9412    0.9407      1668
            MISC     0.8104    0.8405    0.8252       702
             ORG     0.9107    0.9151    0.9129      1661
             PER     0.9800    0.9722    0.9761      1617

all (micro avg.)     0.9261    0.9299    0.9280      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 92.65
                  precision    recall  f1-score   support

             LOC     0.9429    0.9406    0.9418      1668
            MISC     0.8145    0.8319    0.8231       702
             ORG     0.9021    0.9157    0.9089      1661
             PER     0.9758    0.9728    0.9743      1617

all (micro avg.)     0.9239    0.9290    0.9265      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 92.68
                  precision    recall  f1-score   support

             LOC     0.9467    0.9371    0.9418      1668
            MISC     0.8137    0.8276    0.8206       702
             ORG     0.8985    0.9223    0.9103      1661
             PER     0.9818    0.9691    0.9754      1617

all (micro avg.)     0.9253    0.9283    0.9268      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 92.62
                  precision    recall  f1-score   support

             LOC     0.9453    0.9329    0.9390      1668
            MISC     0.8295    0.8248    0.8271       702
             ORG     0.9005    0.9157    0.9081      1661
             PER     0.9723    0.9771    0.9747      1617

all (micro avg.)     0.9254    0.9271    0.9262      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 92.68
                  precision    recall  f1-score   support

             LOC     0.9387    0.9365    0.9376      1668
            MISC     0.8208    0.8419    0.8312       702
             ORG     0.9094    0.9121    0.9107      1661
             PER     0.9752    0.9734    0.9743      1617

all (micro avg.)     0.9255    0.9281    0.9268      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 92.49
                  precision    recall  f1-score   support

             LOC     0.9231    0.9424    0.9327      1668
            MISC     0.8117    0.8476    0.8293       702
             ORG     0.9095    0.9073    0.9084      1661
             PER     0.9789    0.9740    0.9764      1617

all (micro avg.)     0.9206    0.9294    0.9249      5648

----------------------------------------------------------------------

** Worst ** model scores - run 0
                  precision    recall  f1-score   support

             LOC     0.9393    0.9365    0.9379      1668
            MISC     0.8161    0.8219    0.8190       702
             ORG     0.8934    0.9187    0.9059      1661
             PER     0.9757    0.9672    0.9714      1617

all (micro avg.)     0.9204    0.9258    0.9231      5648


** Best ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9401    0.9412    0.9407      1668
            MISC     0.8104    0.8405    0.8252       702
             ORG     0.9107    0.9151    0.9129      1661
             PER     0.9800    0.9722    0.9761      1617

all (micro avg.)     0.9261    0.9299    0.9280      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9385    0.9384    0.9384      1668
            MISC     0.8204    0.8338    0.8269       702
             ORG     0.9035    0.9137    0.9085      1661
             PER     0.9745    0.9729    0.9737      1617

all (micro avg.)     0.9235    0.9280    0.9257 



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF --embedding glove-840B --use-ELMo --fold-count 10


training runtime: 19883.839 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 92.35
                  precision    recall  f1-score   support

             LOC     0.9394    0.9382    0.9388      1668
            MISC     0.8110    0.8191    0.8150       702
             ORG     0.8939    0.9181    0.9059      1661
             PER     0.9776    0.9697    0.9736      1617

all (micro avg.)     0.9205    0.9265    0.9235      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 92.44
                  precision    recall  f1-score   support

             LOC     0.9388    0.9382    0.9385      1668
            MISC     0.8019    0.8248    0.8132       702
             ORG     0.9008    0.9181    0.9094      1661
             PER     0.9806    0.9691    0.9748      1617

all (micro avg.)     0.9218    0.9271    0.9244      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 92.27
                  precision    recall  f1-score   support

             LOC     0.9437    0.9341    0.9388      1668
            MISC     0.8161    0.8091    0.8126       702
             ORG     0.8901    0.9163    0.9030      1661
             PER     0.9752    0.9734    0.9743      1617

all (micro avg.)     0.9208    0.9246    0.9227      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 92.51
                  precision    recall  f1-score   support

             LOC     0.9331    0.9371    0.9351      1668
            MISC     0.8307    0.8177    0.8241       702
             ORG     0.9036    0.9139    0.9087      1661
             PER     0.9770    0.9734    0.9752      1617

all (micro avg.)     0.9243    0.9258    0.9251      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 92.50
                  precision    recall  f1-score   support

             LOC     0.9375    0.9359    0.9367      1668
            MISC     0.8031    0.8248    0.8138       702
             ORG     0.9077    0.9181    0.9129      1661
             PER     0.9776    0.9716    0.9746      1617

all (micro avg.)     0.9230    0.9271    0.9250      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 92.57
                  precision    recall  f1-score   support

             LOC     0.9400    0.9394    0.9397      1668
            MISC     0.8184    0.8219    0.8202       702
             ORG     0.8991    0.9121    0.9056      1661
             PER     0.9807    0.9753    0.9780      1617

all (micro avg.)     0.9243    0.9271    0.9257      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 92.32
                  precision    recall  f1-score   support

             LOC     0.9378    0.9400    0.9389      1668
            MISC     0.7948    0.8333    0.8136       702
             ORG     0.9020    0.9085    0.9052      1661
             PER     0.9764    0.9722    0.9743      1617

all (micro avg.)     0.9197    0.9267    0.9232      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 92.52
                  precision    recall  f1-score   support

             LOC     0.9412    0.9406    0.9409      1668
            MISC     0.8130    0.8177    0.8153       702
             ORG     0.8976    0.9181    0.9077      1661
             PER     0.9758    0.9740    0.9749      1617

all (micro avg.)     0.9221    0.9283    0.9252      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 92.46
                  precision    recall  f1-score   support

             LOC     0.9316    0.9388    0.9352      1668
            MISC     0.8114    0.8333    0.8222       702
             ORG     0.9120    0.9043    0.9081      1661
             PER     0.9765    0.9746    0.9755      1617

all (micro avg.)     0.9234    0.9258    0.9246      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 92.42
                  precision    recall  f1-score   support

             LOC     0.9365    0.9376    0.9371      1668
            MISC     0.8076    0.8191    0.8133       702
             ORG     0.9113    0.9097    0.9105      1661
             PER     0.9764    0.9709    0.9736      1617

all (micro avg.)     0.9242    0.9242    0.9242      5648

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9437    0.9341    0.9388      1668
            MISC     0.8161    0.8091    0.8126       702
             ORG     0.8901    0.9163    0.9030      1661
             PER     0.9752    0.9734    0.9743      1617

all (micro avg.)     0.9208    0.9246    0.9227      5648


** Best ** model scores - run 5
                  precision    recall  f1-score   support

             LOC     0.9400    0.9394    0.9397      1668
            MISC     0.8184    0.8219    0.8202       702
             ORG     0.8991    0.9121    0.9056      1661
             PER     0.9807    0.9753    0.9780      1617

all (micro avg.)     0.9243    0.9271    0.9257      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9380    0.9380    0.9380      1668
            MISC     0.8108    0.8221    0.8163       702
             ORG     0.9018    0.9137    0.9077      1661
             PER     0.9774    0.9724    0.9749      1617

all (micro avg.)     0.9224    0.9263    0.9244


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_ChainCRF --embedding glove-840B --use-ELMo --fold-count 10  --train-with-validation-set

(note: nb epoch = 50)

training runtime: 44356.547 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 92.97
                  precision    recall  f1-score   support

             LOC     0.9459    0.9430    0.9445      1668
            MISC     0.8286    0.8333    0.8310       702
             ORG     0.9064    0.9211    0.9137      1661
             PER     0.9746    0.9734    0.9740      1617

all (micro avg.)     0.9277    0.9317    0.9297      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 92.75
                  precision    recall  f1-score   support

             LOC     0.9383    0.9388    0.9386      1668
            MISC     0.8371    0.8348    0.8359       702
             ORG     0.9043    0.9163    0.9103      1661
             PER     0.9758    0.9716    0.9737      1617

all (micro avg.)     0.9264    0.9286    0.9275      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 93.06
                  precision    recall  f1-score   support

             LOC     0.9425    0.9430    0.9428      1668
            MISC     0.8459    0.8447    0.8453       702
             ORG     0.9006    0.9223    0.9114      1661
             PER     0.9794    0.9709    0.9752      1617

all (micro avg.)     0.9284    0.9327    0.9306      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 93.21
                  precision    recall  f1-score   support

             LOC     0.9420    0.9448    0.9434      1668
            MISC     0.8491    0.8419    0.8455       702
             ORG     0.9067    0.9241    0.9153      1661
             PER     0.9782    0.9728    0.9755      1617

all (micro avg.)     0.9303    0.9340    0.9321      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 92.89
                  precision    recall  f1-score   support

             LOC     0.9478    0.9359    0.9418      1668
            MISC     0.8394    0.8262    0.8327       702
             ORG     0.8977    0.9241    0.9107      1661
             PER     0.9795    0.9728    0.9761      1617

all (micro avg.)     0.9284    0.9294    0.9289      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 92.77
                  precision    recall  f1-score   support

             LOC     0.9405    0.9382    0.9394      1668
            MISC     0.8222    0.8234    0.8228       702
             ORG     0.9095    0.9199    0.9147      1661
             PER     0.9729    0.9765    0.9747      1617

all (micro avg.)     0.9259    0.9295    0.9277      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 92.95
                  precision    recall  f1-score   support

             LOC     0.9412    0.9406    0.9409      1668
            MISC     0.8381    0.8333    0.8357       702
             ORG     0.9050    0.9181    0.9115      1661
             PER     0.9759    0.9777    0.9768      1617

all (micro avg.)     0.9277    0.9313    0.9295      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 92.89
                  precision    recall  f1-score   support

             LOC     0.9437    0.9442    0.9440      1668
            MISC     0.8257    0.8234    0.8245       702
             ORG     0.9030    0.9193    0.9111      1661
             PER     0.9795    0.9746    0.9771      1617

all (micro avg.)     0.9271    0.9306    0.9289      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 92.92
                  precision    recall  f1-score   support

             LOC     0.9430    0.9430    0.9430      1668
            MISC     0.8312    0.8348    0.8330       702
             ORG     0.9030    0.9193    0.9111      1661
             PER     0.9776    0.9734    0.9755      1617

all (micro avg.)     0.9270    0.9313    0.9292      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 93.08
                  precision    recall  f1-score   support

             LOC     0.9464    0.9418    0.9441      1668
            MISC     0.8312    0.8348    0.8330       702
             ORG     0.9078    0.9247    0.9162      1661
             PER     0.9752    0.9746    0.9749      1617

all (micro avg.)     0.9288    0.9329    0.9308      5648

----------------------------------------------------------------------

** Worst ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9383    0.9388    0.9386      1668
            MISC     0.8371    0.8348    0.8359       702
             ORG     0.9043    0.9163    0.9103      1661
             PER     0.9758    0.9716    0.9737      1617

all (micro avg.)     0.9264    0.9286    0.9275      5648


** Best ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9420    0.9448    0.9434      1668
            MISC     0.8491    0.8419    0.8455       702
             ORG     0.9067    0.9241    0.9153      1661
             PER     0.9782    0.9728    0.9755      1617

all (micro avg.)     0.9303    0.9340    0.9321      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9431    0.9414    0.9422      1668
            MISC     0.8349    0.8330    0.8339       702
             ORG     0.9044    0.9210    0.9126      1661
             PER     0.9769    0.9738    0.9753      1617

all (micro avg.)     0.9278    0.9312    0.9295   



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT --transformer bert-base-cased --fold-count 10


training runtime: 16152.433 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights0.hdf5
    f1: 91.15
    precision: 90.33
    recall: 91.98

------------------------ fold 1 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights1.hdf5
    f1: 91.27
    precision: 90.50
    recall: 92.05

------------------------ fold 2 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights2.hdf5
    f1: 91.20
    precision: 90.33
    recall: 92.09

------------------------ fold 3 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights3.hdf5
    f1: 90.89
    precision: 89.90
    recall: 91.89

------------------------ fold 4 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
    f1: 91.00
    precision: 90.16
    recall: 91.86

------------------------ fold 5 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights5.hdf5
    f1: 91.13
    precision: 90.40
    recall: 91.87

------------------------ fold 6 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights6.hdf5
    f1: 91.09
    precision: 90.05
    recall: 92.16

------------------------ fold 7 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights7.hdf5
    f1: 91.27
    precision: 90.21
    recall: 92.35

------------------------ fold 8 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
    f1: 91.56
    precision: 90.82
    recall: 92.32

------------------------ fold 9 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights9.hdf5
    f1: 91.33
    precision: 90.39
    recall: 92.28
----------------------------------------------------------------------

** Worst ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9302    0.9263    0.9282      1668
            MISC     0.7683    0.8362    0.8008       702
             ORG     0.8740    0.9019    0.8877      1661
             PER     0.9547    0.9647    0.9597      1617

all (micro avg.)     0.8990    0.9189    0.9089      5648


** Best ** model scores - run 8
                  precision    recall  f1-score   support

             LOC     0.9338    0.9388    0.9363      1668
            MISC     0.7791    0.8291    0.8033       702
             ORG     0.8847    0.9103    0.8973      1661
             PER     0.9664    0.9610    0.9637      1617

all (micro avg.)     0.9082    0.9232    0.9156      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9311    0.9326    0.9319      1668
            MISC     0.7728    0.8268    0.7988       702
             ORG     0.8774    0.9080    0.8924      1661
             PER     0.9620    0.9627    0.9624      1617

all (micro avg.)     0.9031    0.9208    0.9119




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT --transformer bert-base-cased --fold-count 10 --train-with-validation-set

training runtime: 18114.053 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights0.hdf5
    f1: 91.58
    precision: 90.69
    recall: 92.49

------------------------ fold 1 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights1.hdf5
    f1: 91.38
    precision: 90.53
    recall: 92.25

------------------------ fold 2 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights2.hdf5
    f1: 91.20
    precision: 90.21
    recall: 92.21

------------------------ fold 3 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights3.hdf5
    f1: 91.50
    precision: 90.55
    recall: 92.48

------------------------ fold 4 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
    f1: 91.75
    precision: 90.92
    recall: 92.60

------------------------ fold 5 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights5.hdf5
    f1: 91.63
    precision: 90.90
    recall: 92.37

------------------------ fold 6 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights6.hdf5
    f1: 91.64
    precision: 90.91
    recall: 92.39

------------------------ fold 7 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights7.hdf5
    f1: 91.68
    precision: 90.88
    recall: 92.49

------------------------ fold 8 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
    f1: 91.40
    precision: 90.56
    recall: 92.25

------------------------ fold 9 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights9.hdf5
    f1: 91.30
    precision: 90.27
    recall: 92.35
----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9209    0.9353    0.9280      1668
            MISC     0.7788    0.8276    0.8025       702
             ORG     0.8772    0.9121    0.8943      1661
             PER     0.9664    0.9598    0.9631      1617

all (micro avg.)     0.9021    0.9221    0.9120      5648


** Best ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9291    0.9353    0.9322      1668
            MISC     0.7973    0.8405    0.8183       702
             ORG     0.8883    0.9145    0.9012      1661
             PER     0.9618    0.9654    0.9636      1617

all (micro avg.)     0.9092    0.9260    0.9175      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9289    0.9338    0.9313      1668
            MISC     0.7899    0.8278    0.8083       702
             ORG     0.8798    0.9158    0.8974      1661
             PER     0.9649    0.9636    0.9643      1617

all (micro avg.)     0.9064    0.9239    0.9151




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT_CRF --transformer bert-base-cased --fold-count 10

training runtime: 19890.326 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights0.hdf5
    f1: 91.24
    precision: 90.59
    recall: 91.89

------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights1.hdf5
    f1: 91.37
    precision: 90.57
    recall: 92.17

------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights2.hdf5
    f1: 91.50
    precision: 90.83
    recall: 92.19

------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights3.hdf5
    f1: 91.64
    precision: 90.85
    recall: 92.44

------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights4.hdf5
    f1: 91.00
    precision: 90.08
    recall: 91.94

------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights5.hdf5
    f1: 90.92
    precision: 89.85
    recall: 92.01

------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights6.hdf5
    f1: 91.30
    precision: 90.49
    recall: 92.12

------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights7.hdf5
    f1: 91.26
    precision: 90.35
    recall: 92.19

------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights8.hdf5
    f1: 91.03
    precision: 90.20
    recall: 91.87

------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights9.hdf5
    f1: 91.28
    precision: 90.47
    recall: 92.10
----------------------------------------------------------------------

** Worst ** model scores - run 5
                  precision    recall  f1-score   support

             LOC     0.9297    0.9353    0.9325      1668
            MISC     0.7738    0.8234    0.7978       702
             ORG     0.8647    0.9079    0.8858      1661
             PER     0.9604    0.9592    0.9598      1617

all (micro avg.)     0.8985    0.9201    0.9092      5648


** Best ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9319    0.9347    0.9333      1668
            MISC     0.7908    0.8348    0.8122       702
             ORG     0.8806    0.9145    0.8972      1661
             PER     0.9683    0.9629    0.9656      1617

all (micro avg.)     0.9085    0.9244    0.9164      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights3.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9308    0.9334    0.9321      1668
            MISC     0.7792    0.8271    0.8024       702
             ORG     0.8781    0.9087    0.8931      1661
             PER     0.9625    0.9615    0.9620      1617

all (micro avg.)     0.9043    0.9209    0.9125 



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT_CRF --transformer bert-base-cased --fold-count 10 --train-with-validation-set

training runtime: 23106.79 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights0.hdf5
    f1: 91.70
    precision: 90.99
    recall: 92.42

------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights1.hdf5
    f1: 91.43
    precision: 90.47
    recall: 92.40

------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights2.hdf5
    f1: 91.93
    precision: 91.07
    recall: 92.81

------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights3.hdf5
    f1: 91.39
    precision: 90.46
    recall: 92.33

------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights4.hdf5
    f1: 91.78
    precision: 91.21
    recall: 92.37

------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights5.hdf5
    f1: 91.50
    precision: 90.87
    recall: 92.14

------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights6.hdf5
    f1: 91.74
    precision: 91.02
    recall: 92.48

------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights7.hdf5
    f1: 91.73
    precision: 91.07
    recall: 92.40

------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights8.hdf5
    f1: 91.41
    precision: 90.51
    recall: 92.33

------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights9.hdf5
    f1: 91.68
    precision: 90.87
    recall: 92.51
----------------------------------------------------------------------

** Worst ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9368    0.9335    0.9351      1668
            MISC     0.7809    0.8276    0.8036       702
             ORG     0.8721    0.9193    0.8951      1661
             PER     0.9639    0.9586    0.9612      1617

all (micro avg.)     0.9046    0.9233    0.9139      5648


** Best ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9374    0.9335    0.9354      1668
            MISC     0.7868    0.8462    0.8154       702
             ORG     0.8879    0.9199    0.9036      1661
             PER     0.9654    0.9666    0.9660      1617

all (micro avg.)     0.9107    0.9281    0.9193      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights2.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9330    0.9337    0.9333      1668
            MISC     0.7969    0.8266    0.8114       702
             ORG     0.8793    0.9178    0.8981      1661
             PER     0.9651    0.9634    0.9643      1617

all (micro avg.)     0.9085    0.9242    0.9163 



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT_CRF_CHAR --transformer bert-base-cased --fold-count 10

training runtime: 29477.754 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights0.hdf5
    f1: 91.04
    precision: 90.37
    recall: 91.71

------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights1.hdf5
    f1: 91.23
    precision: 90.35
    recall: 92.14

------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights2.hdf5
    f1: 90.72
    precision: 89.66
    recall: 91.80

------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights3.hdf5
    f1: 90.65
    precision: 89.72
    recall: 91.61

------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights4.hdf5
    f1: 91.28
    precision: 90.48
    recall: 92.09

------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights5.hdf5
    f1: 90.40
    precision: 89.43
    recall: 91.40

------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights6.hdf5
    f1: 91.07
    precision: 90.20
    recall: 91.94

------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights7.hdf5
    f1: 91.53
    precision: 90.73
    recall: 92.35

------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights8.hdf5
    f1: 90.40
    precision: 89.13
    recall: 91.71

------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights9.hdf5
    f1: 91.27
    precision: 90.54
    recall: 92.01
----------------------------------------------------------------------

** Worst ** model scores - run 8
                  precision    recall  f1-score   support

             LOC     0.9202    0.9335    0.9268      1668
            MISC     0.6918    0.8376    0.7577       702
             ORG     0.8877    0.8946    0.8912      1661
             PER     0.9706    0.9579    0.9642      1617

all (micro avg.)     0.8913    0.9171    0.9040      5648


** Best ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9238    0.9371    0.9304      1668
            MISC     0.7605    0.8276    0.7926       702
             ORG     0.9012    0.9121    0.9066      1661
             PER     0.9659    0.9629    0.9644      1617

all (micro avg.)     0.9073    0.9235    0.9153      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights7.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9258    0.9327    0.9292      1668
            MISC     0.7543    0.8274    0.7889       702
             ORG     0.8819    0.9076    0.8945      1661
             PER     0.9651    0.9555    0.9603      1617

all (micro avg.)     0.9006    0.9188    0.9096   





> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT_ChainCRF --transformer bert-base-cased --fold-count 10

training runtime: 20233.137 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights0.hdf5
    f1 (micro): 91.10
                  precision    recall  f1-score   support

             LOC     0.9312    0.9329    0.9320      1668
            MISC     0.7607    0.8333    0.7954       702
             ORG     0.8781    0.9061    0.8919      1661
             PER     0.9623    0.9617    0.9620      1617

all (micro avg.)     0.9014    0.9209    0.9110      5648


------------------------ fold 1 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights1.hdf5
    f1 (micro): 91.19
                  precision    recall  f1-score   support

             LOC     0.9342    0.9275    0.9308      1668
            MISC     0.7751    0.8248    0.7992       702
             ORG     0.8804    0.9127    0.8962      1661
             PER     0.9564    0.9623    0.9593      1617

all (micro avg.)     0.9037    0.9203    0.9119      5648


------------------------ fold 2 --------------------------------------
________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights2.hdf5
    f1 (micro): 91.44
                  precision    recall  f1-score   support

             LOC     0.9311    0.9317    0.9314      1668
            MISC     0.7886    0.8447    0.8157       702
             ORG     0.8794    0.9133    0.8960      1661
             PER     0.9570    0.9635    0.9602      1617

all (micro avg.)     0.9044    0.9246    0.9144      5648


------------------------ fold 3 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights3.hdf5
    f1 (micro): 91.28
                  precision    recall  f1-score   support

             LOC     0.9306    0.9323    0.9314      1668
            MISC     0.7802    0.8291    0.8039       702
             ORG     0.8775    0.9145    0.8956      1661
             PER     0.9576    0.9629    0.9602      1617

all (micro avg.)     0.9028    0.9230    0.9128      5648


------------------------ fold 4 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights4.hdf5
    f1 (micro): 91.16
                  precision    recall  f1-score   support

             LOC     0.9399    0.9275    0.9336      1668
            MISC     0.7864    0.8234    0.8045       702
             ORG     0.8678    0.9127    0.8897      1661
             PER     0.9592    0.9604    0.9598      1617

all (micro avg.)     0.9038    0.9196    0.9116      5648


------------------------ fold 5 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights5.hdf5
    f1 (micro): 90.99
                  precision    recall  f1-score   support

             LOC     0.9331    0.9359    0.9345      1668
            MISC     0.7797    0.8219    0.8003       702
             ORG     0.8681    0.9115    0.8893      1661
             PER     0.9577    0.9530    0.9554      1617

all (micro avg.)     0.9006    0.9194    0.9099      5648


------------------------ fold 6 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights6.hdf5
    f1 (micro): 91.48
                  precision    recall  f1-score   support

             LOC     0.9380    0.9335    0.9357      1668
            MISC     0.7839    0.8063    0.7949       702
             ORG     0.8694    0.9302    0.8988      1661
             PER     0.9693    0.9573    0.9633      1617

all (micro avg.)     0.9062    0.9235    0.9148      5648


------------------------ fold 7 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights7.hdf5
    f1 (micro): 90.77
                  precision    recall  f1-score   support

             LOC     0.9242    0.9281    0.9261      1668
            MISC     0.7702    0.8162    0.7925       702
             ORG     0.8744    0.8970    0.8856      1661
             PER     0.9670    0.9598    0.9634      1617

all (micro avg.)     0.9014    0.9141    0.9077      5648


------------------------ fold 8 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights8.hdf5
    f1 (micro): 91.52
                  precision    recall  f1-score   support

             LOC     0.9361    0.9317    0.9339      1668
            MISC     0.7715    0.8319    0.8005       702
             ORG     0.8872    0.9139    0.9004      1661
             PER     0.9623    0.9641    0.9632      1617

all (micro avg.)     0.9073    0.9233    0.9152      5648


------------------------ fold 9 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights9.hdf5
    f1 (micro): 91.24
                  precision    recall  f1-score   support

             LOC     0.9350    0.9317    0.9333      1668
            MISC     0.7764    0.8262    0.8006       702
             ORG     0.8787    0.9115    0.8948      1661
             PER     0.9603    0.9586    0.9595      1617

all (micro avg.)     0.9046    0.9203    0.9124      5648

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9242    0.9281    0.9261      1668
            MISC     0.7702    0.8162    0.7925       702
             ORG     0.8744    0.8970    0.8856      1661
             PER     0.9670    0.9598    0.9634      1617

all (micro avg.)     0.9014    0.9141    0.9077      5648


** Best ** model scores - run 8
                  precision    recall  f1-score   support

             LOC     0.9361    0.9317    0.9339      1668
            MISC     0.7715    0.8319    0.8005       702
             ORG     0.8872    0.9139    0.9004      1661
             PER     0.9623    0.9641    0.9632      1617

all (micro avg.)     0.9073    0.9233    0.9152      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_ChainCRF/model_weights8.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9333    0.9312    0.9323      1668
            MISC     0.7773    0.8258    0.8007       702
             ORG     0.8761    0.9123    0.8938      1661
             PER     0.9609    0.9604    0.9606      1617

all (micro avg.)     0.9036    0.9209    0.9122       

